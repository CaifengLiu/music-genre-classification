{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Flatten, Lambda, Dropout, Activation, LSTM, GRU, \\\n",
    "        TimeDistributed, Convolution1D, MaxPooling1D, Convolution2D, MaxPooling2D, \\\n",
    "        BatchNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, \\\n",
    "        ZeroPadding2D, Reshape, merge, GlobalAveragePooling2D, GlobalMaxPooling2D, AveragePooling2D\n",
    "from keras.layers.local import LocallyConnected1D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import load_model  \n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def base_conv_block(num_conv_filters, kernel_size):\n",
    "    def f(input_):\n",
    "        x = BatchNormalization()(input_)\n",
    "        x = Activation('relu')(x)\n",
    "        out = Convolution2D(num_conv_filters, kernel_size, padding='same')(x)\n",
    "        return out\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multi_scale_block(num_conv_filters):\n",
    "    def f(input_):\n",
    "        branch1x1 = base_conv_block(num_conv_filters, 1)(input_)\n",
    "        \n",
    "        branch3x3 = base_conv_block(num_conv_filters, 1)(input_)  \n",
    "        branch3x3 = base_conv_block(num_conv_filters, 3)(branch3x3)  \n",
    "  \n",
    "        branch5x5 = base_conv_block(num_conv_filters, 1)(input_)  \n",
    "        branch5x5 = base_conv_block(num_conv_filters, 5)(branch5x5) \n",
    "  \n",
    "        branchpool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(input_)  \n",
    "        branchpool = base_conv_block(num_conv_filters, 1)(branchpool) \n",
    "        \n",
    "        out = concatenate([branch1x1,branch3x3,branch5x5,branchpool], axis=-1)\n",
    "#         out = base_conv_block(num_conv_filters, 1)(out)\n",
    "        return out\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dense_block(num_dense_blocks, num_conv_filters):\n",
    "    def f(input_):\n",
    "        x = input_\n",
    "        for _ in range(num_dense_blocks):\n",
    "            out = multi_scale_block(num_conv_filters)(x)\n",
    "            x = concatenate([x, out], axis=-1)\n",
    "        return x\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transition_block(num_conv_filters):\n",
    "    def f(input_):\n",
    "        x = BatchNormalization()(input_)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Convolution2D(num_conv_filters, 1)(x)\n",
    "        out = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "        return out\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multi_scale_level_cnn(input_shape, num_dense_blocks, num_conv_filters, num_classes):\n",
    "    model_input = Input(shape=input_shape)\n",
    "    \n",
    "    x = Convolution2D(num_conv_filters, 3, padding='same')(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 1))(x)\n",
    "    \n",
    "    x = dense_block(num_dense_blocks, num_conv_filters)(x)\n",
    "    x = transition_block(num_conv_filters)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    model_output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_data_for_conv2D(X, resize_shape=None):\n",
    "    X_conv2D = []\n",
    "    for sample in X:\n",
    "        sample = np.reshape(sample, newshape=(sample.shape[0], sample.shape[1], 1))\n",
    "        if resize_shape:\n",
    "            sample = resize(sample, output_shape=resize_shape)\n",
    "        X_conv2D.append(sample)\n",
    "    return np.array(X_conv2D, dtype=np.float32)\n",
    "\n",
    "def data_iter(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    idx = list(range(num_samples))\n",
    "    while True:\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            j = idx[i:min(i+batch_size, num_samples)]\n",
    "            yield X[j, :], y[j, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size, val_size, test_size):\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=test_size/(test_size + val_size), stratify=y_val_test)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 647, 128, 1)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_melspec = np.load('/share/音乐分类2/GTZAN/without_split_features/melspec_feature_2048.npy')\n",
    "y = np.load('/share/音乐分类2/GTZAN/onehot_labels.npy')\n",
    "X_melspec = process_data_for_conv2D(X_melspec)\n",
    "print(X_melspec.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 647, 128, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 647, 128, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 647, 128, 32)  128         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 647, 128, 32)  0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 161, 128, 32)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 161, 128, 32)  128         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 161, 128, 32)  128         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 161, 128, 32)  0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 161, 128, 32)  0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 161, 128, 32)  1056        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 161, 128, 32)  1056        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 161, 128, 32)  0           max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 161, 128, 32)  128         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 161, 128, 32)  128         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 161, 128, 32)  128         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 161, 128, 32)  128         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 161, 128, 32)  0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 161, 128, 32)  0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 161, 128, 32)  0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 161, 128, 32)  0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 161, 128, 32)  1056        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 161, 128, 32)  9248        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 161, 128, 32)  25632       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 161, 128, 32)  1056        activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 161, 128, 128) 0           conv2d_2[0][0]                   \n",
      "                                                                   conv2d_4[0][0]                   \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 161, 128, 160) 0           max_pooling2d_1[0][0]            \n",
      "                                                                   concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 161, 128, 160) 640         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 161, 128, 160) 640         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 161, 128, 160) 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 161, 128, 160) 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 161, 128, 32)  5152        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 161, 128, 32)  5152        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 161, 128, 160) 0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 161, 128, 160) 640         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 161, 128, 32)  128         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 161, 128, 32)  128         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 161, 128, 160) 640         max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 161, 128, 160) 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 161, 128, 32)  0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 161, 128, 32)  0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 161, 128, 160) 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 161, 128, 32)  5152        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 161, 128, 32)  9248        activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 161, 128, 32)  25632       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 161, 128, 32)  5152        activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 161, 128, 128) 0           conv2d_8[0][0]                   \n",
      "                                                                   conv2d_10[0][0]                  \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "                                                                   conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 161, 128, 288) 0           concatenate_2[0][0]              \n",
      "                                                                   concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 161, 128, 288) 1152        concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 161, 128, 288) 1152        concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 161, 128, 288) 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 161, 128, 288) 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 161, 128, 32)  9248        activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 161, 128, 32)  9248        activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 161, 128, 288) 0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 161, 128, 288) 1152        concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 161, 128, 32)  128         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 161, 128, 32)  128         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 161, 128, 288) 1152        max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 161, 128, 288) 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 161, 128, 32)  0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 161, 128, 32)  0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 161, 128, 288) 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 161, 128, 32)  9248        activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 161, 128, 32)  9248        activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 161, 128, 32)  25632       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 161, 128, 32)  9248        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 161, 128, 128) 0           conv2d_14[0][0]                  \n",
      "                                                                   conv2d_16[0][0]                  \n",
      "                                                                   conv2d_18[0][0]                  \n",
      "                                                                   conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 161, 128, 416) 0           concatenate_4[0][0]              \n",
      "                                                                   concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 161, 128, 416) 1664        concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 161, 128, 416) 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 161, 128, 32)  13344       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 80, 64, 32)    0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 80, 64, 32)    128         average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 80, 64, 32)    0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 32)            0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            330         global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 190,826\n",
      "Trainable params: 185,642\n",
      "Non-trainable params: 5,184\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#check the architecture of the net\n",
    "model = multi_scale_level_cnn(input_shape=(X_melspec.shape[1], X_melspec.shape[2], X_melspec.shape[3]), \n",
    "                              num_dense_blocks=3, num_conv_filters=32, num_classes=10)\n",
    "# model = get_multi_level_cnn_model_3(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), num_classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 31s - loss: 1.8474 - acc: 0.3175 - val_loss: 5.1491 - val_acc: 0.2300\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 27s - loss: 1.5454 - acc: 0.4213 - val_loss: 3.8600 - val_acc: 0.1800\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 27s - loss: 1.4640 - acc: 0.4875 - val_loss: 6.5657 - val_acc: 0.1200\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.4318 - acc: 0.4937 - val_loss: 6.1418 - val_acc: 0.2600\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 27s - loss: 1.3019 - acc: 0.5413 - val_loss: 3.9806 - val_acc: 0.1700\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2425 - acc: 0.5550 - val_loss: 1.5534 - val_acc: 0.5300\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 27s - loss: 1.2197 - acc: 0.5687 - val_loss: 1.5622 - val_acc: 0.3800\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 27s - loss: 1.1521 - acc: 0.5925 - val_loss: 4.3234 - val_acc: 0.2100\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1196 - acc: 0.6000 - val_loss: 2.2716 - val_acc: 0.2600\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 27s - loss: 1.0386 - acc: 0.6412 - val_loss: 2.1630 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 0.9769 - acc: 0.6650 - val_loss: 2.3069 - val_acc: 0.3500\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 1.0010 - acc: 0.6587 - val_loss: 1.0698 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 0.9306 - acc: 0.6663 - val_loss: 4.1306 - val_acc: 0.2100\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.9985 - acc: 0.6450 - val_loss: 1.2565 - val_acc: 0.5800\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.9445 - acc: 0.6675 - val_loss: 1.6926 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8733 - acc: 0.7050 - val_loss: 1.1877 - val_acc: 0.5400\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.8465 - acc: 0.7175 - val_loss: 1.3741 - val_acc: 0.6400\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.7647 - acc: 0.7225 - val_loss: 1.0619 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.7777 - acc: 0.7313 - val_loss: 1.3835 - val_acc: 0.5400\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7974 - acc: 0.7338 - val_loss: 1.3924 - val_acc: 0.6200\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7180 - acc: 0.7537 - val_loss: 1.5806 - val_acc: 0.5400\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7333 - acc: 0.7412 - val_loss: 1.3426 - val_acc: 0.6400\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7168 - acc: 0.7375 - val_loss: 1.0811 - val_acc: 0.7400\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6969 - acc: 0.7687 - val_loss: 1.4812 - val_acc: 0.5300\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.5818 - acc: 0.8012 - val_loss: 2.0200 - val_acc: 0.4800\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6520 - acc: 0.7850 - val_loss: 2.5932 - val_acc: 0.4600\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.5737 - acc: 0.7900 - val_loss: 2.7523 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.5763 - acc: 0.8125 - val_loss: 1.1824 - val_acc: 0.6300\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.6152 - acc: 0.7750 - val_loss: 1.2863 - val_acc: 0.6300\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5557 - acc: 0.8063 - val_loss: 1.7516 - val_acc: 0.5700\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5528 - acc: 0.8113 - val_loss: 1.1211 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 27s - loss: 0.5392 - acc: 0.8500 - val_loss: 0.9692 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5407 - acc: 0.8238 - val_loss: 1.3442 - val_acc: 0.6600\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 27s - loss: 0.5442 - acc: 0.8213 - val_loss: 3.2288 - val_acc: 0.3500\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4800 - acc: 0.8263 - val_loss: 1.6299 - val_acc: 0.5500\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4687 - acc: 0.8413 - val_loss: 1.0704 - val_acc: 0.6800\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 27s - loss: 0.5363 - acc: 0.8063 - val_loss: 2.6428 - val_acc: 0.3200\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4887 - acc: 0.8238 - val_loss: 1.4483 - val_acc: 0.6300\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4781 - acc: 0.8375 - val_loss: 1.2744 - val_acc: 0.6300\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.3591 - acc: 0.8775 - val_loss: 0.9583 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.4222 - acc: 0.8512 - val_loss: 1.0682 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3694 - acc: 0.8750 - val_loss: 1.2245 - val_acc: 0.6700\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.4182 - acc: 0.8637 - val_loss: 1.5101 - val_acc: 0.6700\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3650 - acc: 0.8725 - val_loss: 0.8657 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.2894 - acc: 0.8962 - val_loss: 0.5811 - val_acc: 0.8700\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.2532 - acc: 0.9250 - val_loss: 0.6714 - val_acc: 0.8100\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.2565 - acc: 0.9250 - val_loss: 0.8422 - val_acc: 0.7300\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.2114 - acc: 0.9400 - val_loss: 0.6030 - val_acc: 0.8600\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2435 - acc: 0.9175 - val_loss: 0.5678 - val_acc: 0.8600\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2256 - acc: 0.9325 - val_loss: 1.6954 - val_acc: 0.6300\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2075 - acc: 0.9300 - val_loss: 0.6667 - val_acc: 0.8500\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.1897 - acc: 0.9463 - val_loss: 0.7505 - val_acc: 0.8100\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.1885 - acc: 0.9463 - val_loss: 0.6983 - val_acc: 0.8300\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.1996 - acc: 0.9387 - val_loss: 0.5724 - val_acc: 0.8700\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2032 - acc: 0.9213 - val_loss: 0.9411 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.1699 - acc: 0.9513 - val_loss: 0.5676 - val_acc: 0.8600\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.1929 - acc: 0.9425 - val_loss: 1.6202 - val_acc: 0.6100\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1620 - acc: 0.9475 - val_loss: 1.2692 - val_acc: 0.7200\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1816 - acc: 0.9387 - val_loss: 0.6591 - val_acc: 0.8400\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1506 - acc: 0.9587 - val_loss: 0.8174 - val_acc: 0.8900\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1673 - acc: 0.9463 - val_loss: 1.8533 - val_acc: 0.5400\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 27s - loss: 0.1260 - acc: 0.9688 - val_loss: 0.6216 - val_acc: 0.8900\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1542 - acc: 0.9550 - val_loss: 0.6798 - val_acc: 0.8800\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1424 - acc: 0.9650 - val_loss: 0.5868 - val_acc: 0.8900\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.1615 - acc: 0.9488 - val_loss: 0.9909 - val_acc: 0.7900\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1894 - acc: 0.9350 - val_loss: 0.9472 - val_acc: 0.7400\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.1366 - acc: 0.9613 - val_loss: 0.8919 - val_acc: 0.7900\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.1108 - acc: 0.9738 - val_loss: 0.7290 - val_acc: 0.8300\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0780 - acc: 0.9800 - val_loss: 0.4829 - val_acc: 0.9000\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.0948 - acc: 0.9750 - val_loss: 0.6308 - val_acc: 0.8400\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0877 - acc: 0.9750 - val_loss: 0.5625 - val_acc: 0.8800\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.1115 - acc: 0.9675 - val_loss: 0.6076 - val_acc: 0.8800\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0954 - acc: 0.9663 - val_loss: 0.5533 - val_acc: 0.8500\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0633 - acc: 0.9900 - val_loss: 0.5029 - val_acc: 0.9000\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0814 - acc: 0.9825 - val_loss: 0.4456 - val_acc: 0.9200\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0719 - acc: 0.9887 - val_loss: 0.4688 - val_acc: 0.9100\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0683 - acc: 0.9838 - val_loss: 0.6174 - val_acc: 0.8900\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0662 - acc: 0.9875 - val_loss: 0.4944 - val_acc: 0.9100\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0557 - acc: 0.9875 - val_loss: 0.4900 - val_acc: 0.9100\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0560 - acc: 0.9875 - val_loss: 0.4494 - val_acc: 0.9100\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0437 - acc: 0.9975 - val_loss: 0.4715 - val_acc: 0.9100\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0551 - acc: 0.9887 - val_loss: 0.4837 - val_acc: 0.9000\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0399 - acc: 0.9950 - val_loss: 0.4952 - val_acc: 0.9100\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0583 - acc: 0.9900 - val_loss: 0.4535 - val_acc: 0.9100\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0607 - acc: 0.9912 - val_loss: 0.5684 - val_acc: 0.8900\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0517 - acc: 0.9900 - val_loss: 0.4856 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0663 - acc: 0.9875 - val_loss: 0.4295 - val_acc: 0.9200\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0412 - acc: 0.9938 - val_loss: 0.4915 - val_acc: 0.9100\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0430 - acc: 0.9938 - val_loss: 0.4860 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0419 - acc: 0.9938 - val_loss: 0.4588 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0415 - acc: 0.9950 - val_loss: 0.4675 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0655 - acc: 0.9850 - val_loss: 0.4587 - val_acc: 0.9100\n",
      "\n",
      "\n",
      "1 fold train loss 0.0157 train acc 0.9988, val loss 0.4456 val acc 0.9200, test loss 0.7069 test acc 0.8000\n",
      "\n",
      "\n",
      "Start 2 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 32s - loss: 1.8110 - acc: 0.3537 - val_loss: 6.6560 - val_acc: 0.2200\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.5597 - acc: 0.4250 - val_loss: 5.1036 - val_acc: 0.2200\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.4610 - acc: 0.4787 - val_loss: 1.9990 - val_acc: 0.3900\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.3774 - acc: 0.5000 - val_loss: 1.6021 - val_acc: 0.5500\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3589 - acc: 0.5075 - val_loss: 1.6287 - val_acc: 0.4700\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2328 - acc: 0.5650 - val_loss: 1.4439 - val_acc: 0.5400\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2278 - acc: 0.5563 - val_loss: 2.9090 - val_acc: 0.3900\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1655 - acc: 0.5837 - val_loss: 1.4191 - val_acc: 0.5700\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1189 - acc: 0.5887 - val_loss: 2.3793 - val_acc: 0.3700\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.0761 - acc: 0.6250 - val_loss: 1.6657 - val_acc: 0.5400\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0930 - acc: 0.5975 - val_loss: 1.5296 - val_acc: 0.5700\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 1.0467 - acc: 0.6400 - val_loss: 1.4242 - val_acc: 0.4300\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 1.0815 - acc: 0.6162 - val_loss: 1.3201 - val_acc: 0.5400\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 1.0181 - acc: 0.6150 - val_loss: 1.2367 - val_acc: 0.5200\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.9746 - acc: 0.6300 - val_loss: 1.2145 - val_acc: 0.6300\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.9428 - acc: 0.6700 - val_loss: 1.5062 - val_acc: 0.4300\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.8709 - acc: 0.6900 - val_loss: 1.2514 - val_acc: 0.6200\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8792 - acc: 0.6963 - val_loss: 1.1586 - val_acc: 0.6800\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8991 - acc: 0.6762 - val_loss: 1.5357 - val_acc: 0.5700\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.8716 - acc: 0.6838 - val_loss: 1.9636 - val_acc: 0.4900\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7833 - acc: 0.7225 - val_loss: 1.1298 - val_acc: 0.6500\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7251 - acc: 0.7537 - val_loss: 1.3653 - val_acc: 0.4900\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7808 - acc: 0.7400 - val_loss: 1.2874 - val_acc: 0.5100\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.7494 - acc: 0.7338 - val_loss: 3.3446 - val_acc: 0.4500\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6993 - acc: 0.7650 - val_loss: 1.1868 - val_acc: 0.6200\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6056 - acc: 0.8125 - val_loss: 0.9940 - val_acc: 0.7400\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.6464 - acc: 0.7613 - val_loss: 1.2464 - val_acc: 0.6200\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.6780 - acc: 0.7788 - val_loss: 0.9772 - val_acc: 0.6300\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.6047 - acc: 0.7925 - val_loss: 1.4651 - val_acc: 0.6200\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5930 - acc: 0.8088 - val_loss: 2.7894 - val_acc: 0.3400\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5551 - acc: 0.8125 - val_loss: 1.3104 - val_acc: 0.6700\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5694 - acc: 0.8050 - val_loss: 1.0908 - val_acc: 0.5700\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5371 - acc: 0.8238 - val_loss: 1.1877 - val_acc: 0.6300\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.5440 - acc: 0.8225 - val_loss: 2.9477 - val_acc: 0.4300\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4493 - acc: 0.8387 - val_loss: 0.8872 - val_acc: 0.7300\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.5359 - acc: 0.8187 - val_loss: 0.8239 - val_acc: 0.7300\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4638 - acc: 0.8213 - val_loss: 1.6390 - val_acc: 0.6600\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4860 - acc: 0.8312 - val_loss: 0.7412 - val_acc: 0.8100\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.5190 - acc: 0.8238 - val_loss: 1.5395 - val_acc: 0.5900\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.3554 - acc: 0.8825 - val_loss: 0.4626 - val_acc: 0.8300\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.3574 - acc: 0.8825 - val_loss: 0.8020 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 27s - loss: 0.3310 - acc: 0.8962 - val_loss: 0.5351 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.3354 - acc: 0.8937 - val_loss: 0.5114 - val_acc: 0.8200\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3126 - acc: 0.8937 - val_loss: 0.5859 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3208 - acc: 0.8988 - val_loss: 0.7110 - val_acc: 0.7700\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.2925 - acc: 0.9038 - val_loss: 1.0130 - val_acc: 0.7600\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.2915 - acc: 0.9113 - val_loss: 0.5895 - val_acc: 0.7800\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.3072 - acc: 0.8775 - val_loss: 0.5254 - val_acc: 0.8200\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.3016 - acc: 0.9050 - val_loss: 0.7458 - val_acc: 0.7200\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2397 - acc: 0.9237 - val_loss: 0.5120 - val_acc: 0.8200\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2435 - acc: 0.9287 - val_loss: 0.7062 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2208 - acc: 0.9425 - val_loss: 0.4833 - val_acc: 0.8700\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.2192 - acc: 0.9325 - val_loss: 0.4926 - val_acc: 0.8400\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 27s - loss: 0.2368 - acc: 0.9287 - val_loss: 0.4481 - val_acc: 0.8300\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2118 - acc: 0.9437 - val_loss: 0.4902 - val_acc: 0.8400\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.2353 - acc: 0.9150 - val_loss: 0.5385 - val_acc: 0.8200\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.2289 - acc: 0.9200 - val_loss: 0.7531 - val_acc: 0.7400\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1995 - acc: 0.9338 - val_loss: 1.2252 - val_acc: 0.7400\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.2036 - acc: 0.9363 - val_loss: 0.6903 - val_acc: 0.8300\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1354 - acc: 0.9600 - val_loss: 0.4559 - val_acc: 0.8700\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1881 - acc: 0.9363 - val_loss: 0.6354 - val_acc: 0.8100\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1962 - acc: 0.9300 - val_loss: 0.4542 - val_acc: 0.8400\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1854 - acc: 0.9425 - val_loss: 0.6278 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1661 - acc: 0.9450 - val_loss: 0.5290 - val_acc: 0.8700\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1353 - acc: 0.9575 - val_loss: 0.3908 - val_acc: 0.9000\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1168 - acc: 0.9625 - val_loss: 0.5614 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 27s - loss: 0.1084 - acc: 0.9738 - val_loss: 0.4005 - val_acc: 0.9100\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.0888 - acc: 0.9800 - val_loss: 0.3167 - val_acc: 0.9100\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0938 - acc: 0.9813 - val_loss: 0.3707 - val_acc: 0.9200\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1019 - acc: 0.9712 - val_loss: 0.6063 - val_acc: 0.7900\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.1403 - acc: 0.9587 - val_loss: 0.3630 - val_acc: 0.8900\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.1033 - acc: 0.9725 - val_loss: 0.5225 - val_acc: 0.8800\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0748 - acc: 0.9825 - val_loss: 0.3224 - val_acc: 0.9200\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0918 - acc: 0.9788 - val_loss: 0.3808 - val_acc: 0.8600\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0618 - acc: 0.9887 - val_loss: 0.3771 - val_acc: 0.8500\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0956 - acc: 0.9762 - val_loss: 0.3736 - val_acc: 0.9100\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0696 - acc: 0.9862 - val_loss: 0.3530 - val_acc: 0.8600\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0719 - acc: 0.9825 - val_loss: 0.3638 - val_acc: 0.8800\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0613 - acc: 0.9875 - val_loss: 0.3392 - val_acc: 0.9100\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0839 - acc: 0.9875 - val_loss: 0.3754 - val_acc: 0.9100\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0650 - acc: 0.9838 - val_loss: 0.3076 - val_acc: 0.8900\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0764 - acc: 0.9800 - val_loss: 0.3413 - val_acc: 0.9100\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0552 - acc: 0.9900 - val_loss: 0.3846 - val_acc: 0.8800\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0683 - acc: 0.9862 - val_loss: 0.3553 - val_acc: 0.9100\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0577 - acc: 0.9887 - val_loss: 0.3436 - val_acc: 0.9100\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0615 - acc: 0.9862 - val_loss: 0.3415 - val_acc: 0.9100\n",
      "\n",
      "\n",
      "2 fold train loss 0.0444 train acc 0.9950, val loss 0.3707 val acc 0.9200, test loss 0.3339 test acc 0.9500\n",
      "\n",
      "\n",
      "Start 3 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 33s - loss: 1.7885 - acc: 0.3588 - val_loss: 9.7874 - val_acc: 0.2600\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.5574 - acc: 0.4387 - val_loss: 6.4862 - val_acc: 0.2800\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.4203 - acc: 0.4913 - val_loss: 2.2645 - val_acc: 0.4100\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.3263 - acc: 0.5400 - val_loss: 3.5568 - val_acc: 0.4400\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.2908 - acc: 0.5438 - val_loss: 2.7762 - val_acc: 0.3800\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2695 - acc: 0.5500 - val_loss: 1.2235 - val_acc: 0.5600\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.1604 - acc: 0.5975 - val_loss: 3.4581 - val_acc: 0.3700\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1276 - acc: 0.6162 - val_loss: 1.5463 - val_acc: 0.5200\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.0726 - acc: 0.6112 - val_loss: 0.9636 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.0106 - acc: 0.6450 - val_loss: 0.8195 - val_acc: 0.7600\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 0.9892 - acc: 0.6500 - val_loss: 1.0747 - val_acc: 0.6200\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 0.9272 - acc: 0.6900 - val_loss: 1.0850 - val_acc: 0.6200\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.8706 - acc: 0.7250 - val_loss: 0.9905 - val_acc: 0.6400\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.9343 - acc: 0.6663 - val_loss: 1.1688 - val_acc: 0.5900\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.8834 - acc: 0.7000 - val_loss: 0.8638 - val_acc: 0.6800\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8204 - acc: 0.7362 - val_loss: 2.2886 - val_acc: 0.3800\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.8529 - acc: 0.6875 - val_loss: 2.3181 - val_acc: 0.4100\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.7923 - acc: 0.7200 - val_loss: 0.7714 - val_acc: 0.7400\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8199 - acc: 0.7225 - val_loss: 1.1212 - val_acc: 0.6300\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7672 - acc: 0.7325 - val_loss: 1.0161 - val_acc: 0.6400\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7044 - acc: 0.7525 - val_loss: 0.9224 - val_acc: 0.6700\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.6587 - acc: 0.7562 - val_loss: 0.5234 - val_acc: 0.8400\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.6759 - acc: 0.7675 - val_loss: 2.4328 - val_acc: 0.5200\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.7301 - acc: 0.7588 - val_loss: 0.5761 - val_acc: 0.7600\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.7184 - acc: 0.7700 - val_loss: 1.3715 - val_acc: 0.6300\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6550 - acc: 0.7913 - val_loss: 1.1936 - val_acc: 0.6600\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.5968 - acc: 0.8113 - val_loss: 1.8576 - val_acc: 0.5100\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.5664 - acc: 0.8025 - val_loss: 1.4496 - val_acc: 0.6400\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.6049 - acc: 0.7950 - val_loss: 0.8704 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5290 - acc: 0.8225 - val_loss: 0.8616 - val_acc: 0.6600\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 27s - loss: 0.5784 - acc: 0.8000 - val_loss: 0.8676 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.4999 - acc: 0.8325 - val_loss: 0.8572 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5057 - acc: 0.8375 - val_loss: 0.8227 - val_acc: 0.7100\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.4654 - acc: 0.8662 - val_loss: 1.4913 - val_acc: 0.6600\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4567 - acc: 0.8588 - val_loss: 0.5616 - val_acc: 0.8200\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4323 - acc: 0.8575 - val_loss: 0.8443 - val_acc: 0.7400\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4724 - acc: 0.8375 - val_loss: 0.4396 - val_acc: 0.8900\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4382 - acc: 0.8425 - val_loss: 0.9248 - val_acc: 0.7900\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4073 - acc: 0.8538 - val_loss: 0.7511 - val_acc: 0.7600\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.3876 - acc: 0.8675 - val_loss: 0.7677 - val_acc: 0.7700\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.4201 - acc: 0.8563 - val_loss: 0.4108 - val_acc: 0.8600\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3581 - acc: 0.8900 - val_loss: 0.9196 - val_acc: 0.7600\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.3418 - acc: 0.8863 - val_loss: 1.6843 - val_acc: 0.5600\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.2966 - acc: 0.9087 - val_loss: 0.5552 - val_acc: 0.8300\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3335 - acc: 0.8912 - val_loss: 0.9226 - val_acc: 0.7800\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3355 - acc: 0.9062 - val_loss: 0.5097 - val_acc: 0.8100\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.2956 - acc: 0.9012 - val_loss: 0.6709 - val_acc: 0.8100\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.3393 - acc: 0.8825 - val_loss: 0.5824 - val_acc: 0.8100\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2845 - acc: 0.9150 - val_loss: 0.9003 - val_acc: 0.7300\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2385 - acc: 0.9213 - val_loss: 0.6912 - val_acc: 0.7800\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2950 - acc: 0.9075 - val_loss: 0.7572 - val_acc: 0.8600\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2565 - acc: 0.9188 - val_loss: 1.0815 - val_acc: 0.7100\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.2634 - acc: 0.9225 - val_loss: 0.5044 - val_acc: 0.7900\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.3460 - acc: 0.8863 - val_loss: 0.5522 - val_acc: 0.8500\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.1548 - acc: 0.9562 - val_loss: 0.3406 - val_acc: 0.8500\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.1510 - acc: 0.9525 - val_loss: 0.4068 - val_acc: 0.8700\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.1450 - acc: 0.9613 - val_loss: 0.2325 - val_acc: 0.8700\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1128 - acc: 0.9750 - val_loss: 0.1283 - val_acc: 0.9700\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.0885 - acc: 0.9813 - val_loss: 0.2542 - val_acc: 0.9400\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1710 - acc: 0.9437 - val_loss: 0.2444 - val_acc: 0.9200\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1182 - acc: 0.9663 - val_loss: 0.3285 - val_acc: 0.9000\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.0867 - acc: 0.9762 - val_loss: 0.2527 - val_acc: 0.9200\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.0880 - acc: 0.9788 - val_loss: 0.3037 - val_acc: 0.8700\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.0828 - acc: 0.9800 - val_loss: 0.2430 - val_acc: 0.9200\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.0973 - acc: 0.9688 - val_loss: 0.3302 - val_acc: 0.8800\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.0905 - acc: 0.9750 - val_loss: 0.4428 - val_acc: 0.8400\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.0780 - acc: 0.9813 - val_loss: 0.3251 - val_acc: 0.8900\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.0812 - acc: 0.9813 - val_loss: 0.3056 - val_acc: 0.9300\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0939 - acc: 0.9750 - val_loss: 0.2165 - val_acc: 0.9300\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1172 - acc: 0.9625 - val_loss: 0.7470 - val_acc: 0.7600\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0771 - acc: 0.9800 - val_loss: 0.2708 - val_acc: 0.9100\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0597 - acc: 0.9862 - val_loss: 0.2991 - val_acc: 0.9000\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0957 - acc: 0.9762 - val_loss: 0.2751 - val_acc: 0.9200\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 27s - loss: 0.1008 - acc: 0.9700 - val_loss: 0.3989 - val_acc: 0.8900\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0675 - acc: 0.9813 - val_loss: 0.2498 - val_acc: 0.9300\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0633 - acc: 0.9875 - val_loss: 0.4188 - val_acc: 0.8600\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0613 - acc: 0.9825 - val_loss: 0.2049 - val_acc: 0.9300\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.0493 - acc: 0.9862 - val_loss: 0.2113 - val_acc: 0.9200\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0517 - acc: 0.9900 - val_loss: 0.1946 - val_acc: 0.9300\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0572 - acc: 0.9825 - val_loss: 0.3052 - val_acc: 0.9000\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0252 - acc: 0.9963 - val_loss: 0.1698 - val_acc: 0.9200\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0382 - acc: 0.9887 - val_loss: 0.2574 - val_acc: 0.9200\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1988 - val_acc: 0.9300\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0403 - acc: 0.9950 - val_loss: 0.2355 - val_acc: 0.9200\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0416 - acc: 0.9938 - val_loss: 0.1979 - val_acc: 0.9200\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0331 - acc: 0.9925 - val_loss: 0.1423 - val_acc: 0.9200\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0356 - acc: 0.9938 - val_loss: 0.1663 - val_acc: 0.9400\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0250 - acc: 0.9963 - val_loss: 0.1688 - val_acc: 0.9300\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0287 - acc: 0.9963 - val_loss: 0.1790 - val_acc: 0.9400\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0159 - acc: 0.9988 - val_loss: 0.2167 - val_acc: 0.9300\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0353 - acc: 0.9912 - val_loss: 0.1956 - val_acc: 0.9400\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0184 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9200\n",
      "\n",
      "\n",
      "3 fold train loss 0.0320 train acc 0.9988, val loss 0.1283 val acc 0.9700, test loss 0.3181 test acc 0.9300\n",
      "\n",
      "\n",
      "Start 4 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 35s - loss: 1.9020 - acc: 0.2900 - val_loss: 9.7558 - val_acc: 0.2200\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 27s - loss: 1.5969 - acc: 0.4213 - val_loss: 7.2774 - val_acc: 0.1700\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.4579 - acc: 0.4675 - val_loss: 2.5166 - val_acc: 0.3800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.4381 - acc: 0.4913 - val_loss: 2.9716 - val_acc: 0.3500\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3564 - acc: 0.5150 - val_loss: 1.8924 - val_acc: 0.4100\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2667 - acc: 0.5438 - val_loss: 1.8555 - val_acc: 0.3400\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2620 - acc: 0.5475 - val_loss: 1.4058 - val_acc: 0.5100\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.2019 - acc: 0.5950 - val_loss: 1.5587 - val_acc: 0.3300\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1385 - acc: 0.6200 - val_loss: 1.4487 - val_acc: 0.5400\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.1085 - acc: 0.6088 - val_loss: 1.4882 - val_acc: 0.5400\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0902 - acc: 0.6325 - val_loss: 1.1079 - val_acc: 0.6100\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 1.0478 - acc: 0.6325 - val_loss: 1.5898 - val_acc: 0.4200\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 1.0003 - acc: 0.6525 - val_loss: 0.8977 - val_acc: 0.7100\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.9144 - acc: 0.6875 - val_loss: 1.3893 - val_acc: 0.5900\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.9442 - acc: 0.6762 - val_loss: 0.7099 - val_acc: 0.7700\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8571 - acc: 0.7013 - val_loss: 0.9552 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.8556 - acc: 0.7200 - val_loss: 1.3109 - val_acc: 0.6500\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8575 - acc: 0.7150 - val_loss: 1.9547 - val_acc: 0.4800\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.7686 - acc: 0.7375 - val_loss: 0.7906 - val_acc: 0.7300\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7229 - acc: 0.7450 - val_loss: 1.1139 - val_acc: 0.6300\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7752 - acc: 0.7288 - val_loss: 1.0809 - val_acc: 0.7200\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7193 - acc: 0.7550 - val_loss: 0.7144 - val_acc: 0.7700\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.6332 - acc: 0.8000 - val_loss: 0.6741 - val_acc: 0.7900\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.7103 - acc: 0.7537 - val_loss: 0.8595 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6779 - acc: 0.7738 - val_loss: 0.9683 - val_acc: 0.6800\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6660 - acc: 0.7850 - val_loss: 0.9047 - val_acc: 0.6900\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.5555 - acc: 0.8200 - val_loss: 1.9924 - val_acc: 0.5800\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.6540 - acc: 0.7725 - val_loss: 0.5726 - val_acc: 0.8400\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5171 - acc: 0.8287 - val_loss: 0.6089 - val_acc: 0.7900\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5515 - acc: 0.8238 - val_loss: 0.7759 - val_acc: 0.7200\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5388 - acc: 0.8063 - val_loss: 0.6703 - val_acc: 0.7800\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5463 - acc: 0.8125 - val_loss: 0.5558 - val_acc: 0.7900\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.4845 - acc: 0.8462 - val_loss: 1.1626 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.4710 - acc: 0.8438 - val_loss: 0.7311 - val_acc: 0.7200\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4482 - acc: 0.8575 - val_loss: 1.7298 - val_acc: 0.5800\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4298 - acc: 0.8688 - val_loss: 0.5051 - val_acc: 0.8200\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 27s - loss: 0.4786 - acc: 0.8538 - val_loss: 1.2038 - val_acc: 0.6700\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4214 - acc: 0.8662 - val_loss: 0.4799 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.3876 - acc: 0.8700 - val_loss: 0.9712 - val_acc: 0.6500\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.3839 - acc: 0.8738 - val_loss: 2.4863 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.4462 - acc: 0.8550 - val_loss: 0.6628 - val_acc: 0.7900\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3409 - acc: 0.8900 - val_loss: 0.8002 - val_acc: 0.6700\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.4126 - acc: 0.8650 - val_loss: 1.2076 - val_acc: 0.6700\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3612 - acc: 0.8650 - val_loss: 2.0410 - val_acc: 0.6500\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3066 - acc: 0.9188 - val_loss: 0.5180 - val_acc: 0.8900\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.2911 - acc: 0.9025 - val_loss: 1.0221 - val_acc: 0.6900\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.3153 - acc: 0.8863 - val_loss: 1.4029 - val_acc: 0.5800\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.2770 - acc: 0.9137 - val_loss: 2.2219 - val_acc: 0.5500\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.2775 - acc: 0.9062 - val_loss: 0.6128 - val_acc: 0.8100\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2707 - acc: 0.9150 - val_loss: 1.2731 - val_acc: 0.7200\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2537 - acc: 0.9213 - val_loss: 0.5955 - val_acc: 0.8100\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2547 - acc: 0.9225 - val_loss: 1.6321 - val_acc: 0.6300\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 27s - loss: 0.2896 - acc: 0.9000 - val_loss: 2.1211 - val_acc: 0.4300\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.2600 - acc: 0.9188 - val_loss: 0.6888 - val_acc: 0.8200\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2261 - acc: 0.9200 - val_loss: 1.2339 - val_acc: 0.6900\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.2728 - acc: 0.9175 - val_loss: 0.6451 - val_acc: 0.7900\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.2019 - acc: 0.9387 - val_loss: 0.4693 - val_acc: 0.8800\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.2254 - acc: 0.9237 - val_loss: 1.4718 - val_acc: 0.6800\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1741 - acc: 0.9513 - val_loss: 0.5941 - val_acc: 0.8200\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.2545 - acc: 0.9137 - val_loss: 1.5606 - val_acc: 0.6900\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.2522 - acc: 0.9125 - val_loss: 0.4718 - val_acc: 0.8500\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1981 - acc: 0.9350 - val_loss: 0.3826 - val_acc: 0.8600\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1642 - acc: 0.9463 - val_loss: 0.7246 - val_acc: 0.7900\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.2213 - acc: 0.9237 - val_loss: 1.7445 - val_acc: 0.6800\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.2083 - acc: 0.9350 - val_loss: 1.1907 - val_acc: 0.6600\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.2115 - acc: 0.9313 - val_loss: 1.7990 - val_acc: 0.6600\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 29s - loss: 0.2004 - acc: 0.9400 - val_loss: 0.5660 - val_acc: 0.8700\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.1251 - acc: 0.9663 - val_loss: 0.4491 - val_acc: 0.8600\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0935 - acc: 0.9750 - val_loss: 0.4896 - val_acc: 0.8600\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.0746 - acc: 0.9825 - val_loss: 0.5203 - val_acc: 0.8400\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0794 - acc: 0.9838 - val_loss: 0.4340 - val_acc: 0.8800\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0897 - acc: 0.9800 - val_loss: 0.4980 - val_acc: 0.8700\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0648 - acc: 0.9912 - val_loss: 0.5515 - val_acc: 0.8600\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0717 - acc: 0.9850 - val_loss: 0.4504 - val_acc: 0.8600\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0829 - acc: 0.9775 - val_loss: 0.5642 - val_acc: 0.8400\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.1031 - acc: 0.9675 - val_loss: 0.5592 - val_acc: 0.8700\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0719 - acc: 0.9750 - val_loss: 0.8769 - val_acc: 0.8200\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0583 - acc: 0.9875 - val_loss: 0.4117 - val_acc: 0.8900\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0464 - acc: 0.9838 - val_loss: 0.4718 - val_acc: 0.8800\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0739 - acc: 0.9800 - val_loss: 0.3479 - val_acc: 0.8900\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0511 - acc: 0.9887 - val_loss: 0.5224 - val_acc: 0.8800\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0506 - acc: 0.9887 - val_loss: 0.4922 - val_acc: 0.8800\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 27s - loss: 0.0521 - acc: 0.9875 - val_loss: 0.4582 - val_acc: 0.8800\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0469 - acc: 0.9887 - val_loss: 0.4212 - val_acc: 0.8700\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0470 - acc: 0.9900 - val_loss: 0.3716 - val_acc: 0.8800\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0408 - acc: 0.9950 - val_loss: 0.4125 - val_acc: 0.8800\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0282 - acc: 0.9963 - val_loss: 0.4319 - val_acc: 0.8900\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0348 - acc: 0.9938 - val_loss: 0.4383 - val_acc: 0.8800\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0503 - acc: 0.9862 - val_loss: 0.4981 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0272 - acc: 0.9975 - val_loss: 0.4444 - val_acc: 0.8900\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0345 - acc: 0.9963 - val_loss: 0.4028 - val_acc: 0.9100\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 27s - loss: 0.0304 - acc: 0.9938 - val_loss: 0.4248 - val_acc: 0.9100\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0368 - acc: 0.9912 - val_loss: 0.3885 - val_acc: 0.8900\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0370 - acc: 0.9925 - val_loss: 0.4498 - val_acc: 0.8600\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0333 - acc: 0.9938 - val_loss: 0.4313 - val_acc: 0.8900\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 28s - loss: 0.0251 - acc: 0.9975 - val_loss: 0.4114 - val_acc: 0.8900\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 28s - loss: 0.0410 - acc: 0.9912 - val_loss: 0.4287 - val_acc: 0.8900\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 28s - loss: 0.0437 - acc: 0.9887 - val_loss: 0.4197 - val_acc: 0.9000\n",
      "\n",
      "\n",
      "4 fold train loss 0.0072 train acc 0.9988, val loss 0.4028 val acc 0.9100, test loss 0.2514 test acc 0.9300\n",
      "\n",
      "\n",
      "Start 5 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 39s - loss: 1.8723 - acc: 0.3100 - val_loss: 3.8567 - val_acc: 0.3300\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.6247 - acc: 0.4188 - val_loss: 3.0053 - val_acc: 0.2400\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.5376 - acc: 0.4363 - val_loss: 1.6792 - val_acc: 0.5200\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.4794 - acc: 0.4750 - val_loss: 1.6083 - val_acc: 0.4800\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3615 - acc: 0.5125 - val_loss: 1.8593 - val_acc: 0.4900\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.3170 - acc: 0.5375 - val_loss: 2.3682 - val_acc: 0.4300\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2509 - acc: 0.5588 - val_loss: 1.6038 - val_acc: 0.5800\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1925 - acc: 0.5913 - val_loss: 1.0327 - val_acc: 0.6400\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1818 - acc: 0.5775 - val_loss: 1.6553 - val_acc: 0.5200\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.1221 - acc: 0.6213 - val_loss: 1.2874 - val_acc: 0.5500\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0409 - acc: 0.6488 - val_loss: 1.7510 - val_acc: 0.4700\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 0.9911 - acc: 0.6488 - val_loss: 1.2097 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 0.9191 - acc: 0.6838 - val_loss: 1.6134 - val_acc: 0.6200\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.9271 - acc: 0.6750 - val_loss: 3.7983 - val_acc: 0.3400\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.8825 - acc: 0.7000 - val_loss: 1.4485 - val_acc: 0.5900\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 27s - loss: 0.8996 - acc: 0.6863 - val_loss: 2.0132 - val_acc: 0.4700\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.9321 - acc: 0.6775 - val_loss: 1.5128 - val_acc: 0.6100\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8382 - acc: 0.7250 - val_loss: 1.2890 - val_acc: 0.6300\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8367 - acc: 0.7137 - val_loss: 0.8573 - val_acc: 0.6900\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7523 - acc: 0.7387 - val_loss: 0.7869 - val_acc: 0.7200\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.6772 - acc: 0.7675 - val_loss: 0.9070 - val_acc: 0.7700\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.6246 - acc: 0.7788 - val_loss: 1.5521 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.6624 - acc: 0.7675 - val_loss: 0.9129 - val_acc: 0.7100\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6263 - acc: 0.7963 - val_loss: 0.8047 - val_acc: 0.8300\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6203 - acc: 0.7850 - val_loss: 1.2439 - val_acc: 0.6700\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6368 - acc: 0.7887 - val_loss: 2.0057 - val_acc: 0.5500\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.6165 - acc: 0.7900 - val_loss: 1.0132 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.5455 - acc: 0.8137 - val_loss: 0.8831 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5924 - acc: 0.7950 - val_loss: 0.7378 - val_acc: 0.7600\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5148 - acc: 0.8300 - val_loss: 0.7772 - val_acc: 0.7100\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5453 - acc: 0.8187 - val_loss: 0.8637 - val_acc: 0.7700\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5095 - acc: 0.8287 - val_loss: 1.0579 - val_acc: 0.6400\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.4695 - acc: 0.8450 - val_loss: 1.3794 - val_acc: 0.6300\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.4666 - acc: 0.8550 - val_loss: 0.5806 - val_acc: 0.8100\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4237 - acc: 0.8525 - val_loss: 0.9909 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4442 - acc: 0.8450 - val_loss: 2.0809 - val_acc: 0.5900\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4663 - acc: 0.8563 - val_loss: 2.4149 - val_acc: 0.5500\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4138 - acc: 0.8438 - val_loss: 1.3039 - val_acc: 0.6400\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4963 - acc: 0.8300 - val_loss: 1.1278 - val_acc: 0.6700\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 27s - loss: 0.4440 - acc: 0.8475 - val_loss: 1.4751 - val_acc: 0.6100\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.3671 - acc: 0.8775 - val_loss: 0.6953 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3497 - acc: 0.8937 - val_loss: 1.7282 - val_acc: 0.5700\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.3814 - acc: 0.8700 - val_loss: 0.8673 - val_acc: 0.7600\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3175 - acc: 0.9012 - val_loss: 0.6671 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3709 - acc: 0.8800 - val_loss: 1.0052 - val_acc: 0.7100\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3193 - acc: 0.8988 - val_loss: 0.8483 - val_acc: 0.7100\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.3222 - acc: 0.8975 - val_loss: 1.0071 - val_acc: 0.7300\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 29s - loss: 0.3305 - acc: 0.8875 - val_loss: 0.3818 - val_acc: 0.8400\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2099 - acc: 0.9287 - val_loss: 0.3042 - val_acc: 0.9000\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2184 - acc: 0.9375 - val_loss: 0.5170 - val_acc: 0.8200\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2155 - acc: 0.9425 - val_loss: 0.3421 - val_acc: 0.9100\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2015 - acc: 0.9363 - val_loss: 0.3892 - val_acc: 0.8500\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.1791 - acc: 0.9475 - val_loss: 0.3846 - val_acc: 0.8600\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.1636 - acc: 0.9587 - val_loss: 0.3351 - val_acc: 0.9100\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.1511 - acc: 0.9537 - val_loss: 0.4494 - val_acc: 0.8800\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 27s - loss: 0.1633 - acc: 0.9537 - val_loss: 0.2965 - val_acc: 0.9100\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.1467 - acc: 0.9550 - val_loss: 0.3228 - val_acc: 0.8700\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1756 - acc: 0.9500 - val_loss: 0.3764 - val_acc: 0.8800\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1429 - acc: 0.9575 - val_loss: 0.3817 - val_acc: 0.8900\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1327 - acc: 0.9587 - val_loss: 0.4087 - val_acc: 0.8700\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1497 - acc: 0.9500 - val_loss: 1.0511 - val_acc: 0.7200\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1750 - acc: 0.9425 - val_loss: 0.7789 - val_acc: 0.7700\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1366 - acc: 0.9613 - val_loss: 0.2612 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1105 - acc: 0.9700 - val_loss: 0.3298 - val_acc: 0.8900\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1622 - acc: 0.9525 - val_loss: 0.5544 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1055 - acc: 0.9725 - val_loss: 0.3597 - val_acc: 0.9200\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.0944 - acc: 0.9750 - val_loss: 0.2677 - val_acc: 0.9200\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.0987 - acc: 0.9738 - val_loss: 0.5770 - val_acc: 0.8200\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0944 - acc: 0.9712 - val_loss: 0.2656 - val_acc: 0.9300\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1198 - acc: 0.9688 - val_loss: 0.4105 - val_acc: 0.9000\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.1195 - acc: 0.9550 - val_loss: 0.6215 - val_acc: 0.8400\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0658 - acc: 0.9875 - val_loss: 0.2639 - val_acc: 0.9200\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 27s - loss: 0.0522 - acc: 0.9912 - val_loss: 0.3156 - val_acc: 0.9200\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0637 - acc: 0.9875 - val_loss: 0.2583 - val_acc: 0.9400\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0606 - acc: 0.9862 - val_loss: 0.2118 - val_acc: 0.9100\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0589 - acc: 0.9900 - val_loss: 0.2845 - val_acc: 0.8800\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0693 - acc: 0.9800 - val_loss: 0.4097 - val_acc: 0.9000\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0457 - acc: 0.9925 - val_loss: 0.2716 - val_acc: 0.9300\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.0572 - acc: 0.9838 - val_loss: 0.2593 - val_acc: 0.9300\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0465 - acc: 0.9900 - val_loss: 0.2295 - val_acc: 0.9200\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0411 - acc: 0.9950 - val_loss: 0.2563 - val_acc: 0.9500\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0374 - acc: 0.9963 - val_loss: 0.2429 - val_acc: 0.9200\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0545 - acc: 0.9887 - val_loss: 0.3055 - val_acc: 0.9300\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0458 - acc: 0.9887 - val_loss: 0.2654 - val_acc: 0.9400\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0532 - acc: 0.9900 - val_loss: 0.2610 - val_acc: 0.9500\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0420 - acc: 0.9963 - val_loss: 0.2199 - val_acc: 0.9100\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0530 - acc: 0.9887 - val_loss: 0.2120 - val_acc: 0.9300\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0397 - acc: 0.9925 - val_loss: 0.2359 - val_acc: 0.9300\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 27s - loss: 0.0278 - acc: 0.9975 - val_loss: 0.2505 - val_acc: 0.9300\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0297 - acc: 0.9975 - val_loss: 0.2534 - val_acc: 0.9400\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0350 - acc: 0.9925 - val_loss: 0.2769 - val_acc: 0.9400\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0321 - acc: 0.9963 - val_loss: 0.2249 - val_acc: 0.9500\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0250 - acc: 1.0000 - val_loss: 0.2386 - val_acc: 0.9400\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0321 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9300\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0348 - acc: 0.9950 - val_loss: 0.2570 - val_acc: 0.9200\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 28s - loss: 0.0411 - acc: 0.9963 - val_loss: 0.2467 - val_acc: 0.9300\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 28s - loss: 0.0368 - acc: 0.9900 - val_loss: 0.2596 - val_acc: 0.9100\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 27s - loss: 0.0254 - acc: 0.9963 - val_loss: 0.2495 - val_acc: 0.9500\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 28s - loss: 0.0302 - acc: 0.9963 - val_loss: 0.2462 - val_acc: 0.9500\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 28s - loss: 0.0366 - acc: 0.9925 - val_loss: 0.2321 - val_acc: 0.9500\n",
      "\n",
      "\n",
      "5 fold train loss 0.0088 train acc 1.0000, val loss 0.2563 val acc 0.9500, test loss 0.2483 test acc 0.9300\n",
      "\n",
      "\n",
      "Start 6 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 39s - loss: 1.8891 - acc: 0.3100 - val_loss: 9.4367 - val_acc: 0.1600\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.5989 - acc: 0.4200 - val_loss: 9.3099 - val_acc: 0.1400\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.5171 - acc: 0.4612 - val_loss: 7.5459 - val_acc: 0.2400\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.4200 - acc: 0.4862 - val_loss: 8.6847 - val_acc: 0.1200\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3920 - acc: 0.5100 - val_loss: 1.2452 - val_acc: 0.5800\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.3111 - acc: 0.5550 - val_loss: 1.3728 - val_acc: 0.4900\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2192 - acc: 0.5725 - val_loss: 1.3556 - val_acc: 0.5400\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1982 - acc: 0.5988 - val_loss: 1.4357 - val_acc: 0.5400\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1140 - acc: 0.6213 - val_loss: 2.0455 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.0373 - acc: 0.6350 - val_loss: 1.1600 - val_acc: 0.5400\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0071 - acc: 0.6512 - val_loss: 1.1420 - val_acc: 0.7300\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 0.9937 - acc: 0.6625 - val_loss: 0.8061 - val_acc: 0.7100\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 0.9983 - acc: 0.6412 - val_loss: 1.6582 - val_acc: 0.5900\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.9607 - acc: 0.6750 - val_loss: 1.5092 - val_acc: 0.5200\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.9039 - acc: 0.6925 - val_loss: 0.7363 - val_acc: 0.7200\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8265 - acc: 0.7250 - val_loss: 1.5739 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.7963 - acc: 0.7225 - val_loss: 0.9392 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8296 - acc: 0.7175 - val_loss: 0.7906 - val_acc: 0.7300\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8049 - acc: 0.7387 - val_loss: 0.7247 - val_acc: 0.7400\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.6754 - acc: 0.7687 - val_loss: 0.6578 - val_acc: 0.7700\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7051 - acc: 0.7738 - val_loss: 0.8665 - val_acc: 0.7400\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7353 - acc: 0.7463 - val_loss: 0.8650 - val_acc: 0.6300\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.6204 - acc: 0.8000 - val_loss: 0.6325 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6466 - acc: 0.7887 - val_loss: 1.4876 - val_acc: 0.5900\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6094 - acc: 0.7925 - val_loss: 0.4768 - val_acc: 0.8200\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.5491 - acc: 0.8025 - val_loss: 0.7061 - val_acc: 0.7900\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.5925 - acc: 0.8113 - val_loss: 0.7213 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 27s - loss: 0.6080 - acc: 0.8037 - val_loss: 0.7647 - val_acc: 0.7300\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5416 - acc: 0.8337 - val_loss: 0.8488 - val_acc: 0.7800\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5087 - acc: 0.8375 - val_loss: 0.4507 - val_acc: 0.8400\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.4652 - acc: 0.8525 - val_loss: 0.5447 - val_acc: 0.8600\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 27s - loss: 0.5340 - acc: 0.8162 - val_loss: 0.8171 - val_acc: 0.7700\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.4940 - acc: 0.8375 - val_loss: 0.3788 - val_acc: 0.8800\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.4617 - acc: 0.8488 - val_loss: 0.3885 - val_acc: 0.8700\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4100 - acc: 0.8700 - val_loss: 0.6362 - val_acc: 0.8200\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4391 - acc: 0.8725 - val_loss: 1.2226 - val_acc: 0.6700\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4162 - acc: 0.8588 - val_loss: 0.4089 - val_acc: 0.9300\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4530 - acc: 0.8438 - val_loss: 0.6263 - val_acc: 0.7900\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.3928 - acc: 0.8575 - val_loss: 0.3874 - val_acc: 0.8700\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.3610 - acc: 0.8850 - val_loss: 0.4138 - val_acc: 0.8900\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.3241 - acc: 0.9025 - val_loss: 0.4036 - val_acc: 0.9000\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.3123 - acc: 0.8950 - val_loss: 0.3337 - val_acc: 0.9100\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.2879 - acc: 0.9012 - val_loss: 0.8360 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3551 - acc: 0.8912 - val_loss: 0.3935 - val_acc: 0.8800\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3672 - acc: 0.8888 - val_loss: 0.5895 - val_acc: 0.8200\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3109 - acc: 0.8937 - val_loss: 0.3592 - val_acc: 0.8800\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.2589 - acc: 0.9250 - val_loss: 0.4341 - val_acc: 0.8500\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.2769 - acc: 0.9150 - val_loss: 0.3022 - val_acc: 0.8900\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2742 - acc: 0.9100 - val_loss: 0.5348 - val_acc: 0.8300\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2614 - acc: 0.9188 - val_loss: 2.5353 - val_acc: 0.5400\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 30s - loss: 0.2765 - acc: 0.9113 - val_loss: 0.8383 - val_acc: 0.7400\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.1722 - acc: 0.9450 - val_loss: 0.2178 - val_acc: 0.9400\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.1308 - acc: 0.9725 - val_loss: 0.1521 - val_acc: 0.9700\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.1050 - acc: 0.9800 - val_loss: 0.1479 - val_acc: 0.9400\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.1106 - acc: 0.9712 - val_loss: 0.1146 - val_acc: 0.9700\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.1203 - acc: 0.9613 - val_loss: 0.1970 - val_acc: 0.9400\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.0931 - acc: 0.9750 - val_loss: 0.1510 - val_acc: 0.9700\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1207 - acc: 0.9650 - val_loss: 0.1134 - val_acc: 0.9800\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1074 - acc: 0.9650 - val_loss: 0.2757 - val_acc: 0.9400\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1269 - acc: 0.9650 - val_loss: 0.1903 - val_acc: 0.9200\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.0918 - acc: 0.9800 - val_loss: 0.1259 - val_acc: 0.9800\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.0905 - acc: 0.9838 - val_loss: 0.2273 - val_acc: 0.9100\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.0914 - acc: 0.9688 - val_loss: 0.1386 - val_acc: 0.9600\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1312 - acc: 0.9613 - val_loss: 0.3283 - val_acc: 0.9000\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1458 - acc: 0.9525 - val_loss: 0.1886 - val_acc: 0.9400\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.0908 - acc: 0.9788 - val_loss: 0.1522 - val_acc: 0.9500\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.0826 - acc: 0.9775 - val_loss: 0.1055 - val_acc: 0.9700\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.0702 - acc: 0.9788 - val_loss: 0.1859 - val_acc: 0.9400\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0807 - acc: 0.9788 - val_loss: 0.1381 - val_acc: 0.9600\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.0639 - acc: 0.9838 - val_loss: 0.1095 - val_acc: 0.9600\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0431 - acc: 0.9938 - val_loss: 0.1339 - val_acc: 0.9700\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0570 - acc: 0.9850 - val_loss: 0.1339 - val_acc: 0.9700\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0452 - acc: 0.9925 - val_loss: 0.1422 - val_acc: 0.9700\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0614 - acc: 0.9838 - val_loss: 0.1337 - val_acc: 0.9700\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0721 - acc: 0.9825 - val_loss: 0.1370 - val_acc: 0.9700\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0414 - acc: 0.9912 - val_loss: 0.1163 - val_acc: 0.9700\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0399 - acc: 0.9925 - val_loss: 0.1097 - val_acc: 0.9700\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0429 - acc: 0.9925 - val_loss: 0.1116 - val_acc: 0.9800\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0294 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9700\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0288 - acc: 0.9950 - val_loss: 0.1005 - val_acc: 0.9700\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0336 - acc: 0.9963 - val_loss: 0.1002 - val_acc: 0.9700\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0258 - acc: 0.9950 - val_loss: 0.1173 - val_acc: 0.9800\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0303 - acc: 0.9950 - val_loss: 0.1119 - val_acc: 0.9800\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0411 - acc: 0.9925 - val_loss: 0.1094 - val_acc: 0.9700\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0586 - acc: 0.9862 - val_loss: 0.1295 - val_acc: 0.9800\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0417 - acc: 0.9925 - val_loss: 0.1299 - val_acc: 0.9700\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0353 - acc: 0.9950 - val_loss: 0.1416 - val_acc: 0.9800\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0327 - acc: 0.9950 - val_loss: 0.1347 - val_acc: 0.9800\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0283 - acc: 0.9950 - val_loss: 0.1186 - val_acc: 0.9800\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0318 - acc: 0.9925 - val_loss: 0.1185 - val_acc: 0.9700\n",
      "\n",
      "\n",
      "6 fold train loss 0.0515 train acc 0.9912, val loss 0.1134 val acc 0.9800, test loss 0.1700 test acc 0.9600\n",
      "\n",
      "\n",
      "Start 7 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 41s - loss: 1.8105 - acc: 0.3500 - val_loss: 6.1714 - val_acc: 0.1800\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.5264 - acc: 0.4487 - val_loss: 6.2338 - val_acc: 0.1400\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.4740 - acc: 0.4662 - val_loss: 3.6861 - val_acc: 0.3800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.3868 - acc: 0.4950 - val_loss: 2.5058 - val_acc: 0.3800\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3312 - acc: 0.5312 - val_loss: 1.3894 - val_acc: 0.5100\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2302 - acc: 0.5613 - val_loss: 2.1052 - val_acc: 0.4400\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.1167 - acc: 0.6188 - val_loss: 1.5279 - val_acc: 0.4400\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1371 - acc: 0.5962 - val_loss: 1.5569 - val_acc: 0.4600\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 0.9906 - acc: 0.6625 - val_loss: 1.2847 - val_acc: 0.5800\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.0264 - acc: 0.6363 - val_loss: 1.9877 - val_acc: 0.4800\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0406 - acc: 0.6287 - val_loss: 1.6528 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 0.9064 - acc: 0.6863 - val_loss: 1.4349 - val_acc: 0.5700\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 0.9283 - acc: 0.6637 - val_loss: 1.9045 - val_acc: 0.4800\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.9237 - acc: 0.6787 - val_loss: 3.0728 - val_acc: 0.4200\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.9428 - acc: 0.6912 - val_loss: 1.9612 - val_acc: 0.4900\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8506 - acc: 0.7062 - val_loss: 1.1804 - val_acc: 0.6200\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.7947 - acc: 0.7275 - val_loss: 1.2308 - val_acc: 0.5800\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8055 - acc: 0.7163 - val_loss: 1.2396 - val_acc: 0.6400\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.7982 - acc: 0.7313 - val_loss: 1.4461 - val_acc: 0.5400\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7075 - acc: 0.7562 - val_loss: 1.4495 - val_acc: 0.6700\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.8039 - acc: 0.7275 - val_loss: 1.0658 - val_acc: 0.6700\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.6907 - acc: 0.7775 - val_loss: 1.1305 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7303 - acc: 0.7588 - val_loss: 1.1868 - val_acc: 0.6700\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6944 - acc: 0.7788 - val_loss: 2.0321 - val_acc: 0.5400\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6567 - acc: 0.7875 - val_loss: 0.9887 - val_acc: 0.6500\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6513 - acc: 0.8063 - val_loss: 1.2516 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.5739 - acc: 0.8000 - val_loss: 1.0853 - val_acc: 0.6900\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 27s - loss: 0.6547 - acc: 0.7712 - val_loss: 1.1130 - val_acc: 0.6900\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5798 - acc: 0.8012 - val_loss: 1.3648 - val_acc: 0.5600\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5820 - acc: 0.8137 - val_loss: 1.5294 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5238 - acc: 0.8187 - val_loss: 0.9603 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5474 - acc: 0.8213 - val_loss: 1.3049 - val_acc: 0.6100\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5628 - acc: 0.8025 - val_loss: 1.1069 - val_acc: 0.6300\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.5346 - acc: 0.8337 - val_loss: 1.8075 - val_acc: 0.6100\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4272 - acc: 0.8563 - val_loss: 0.8293 - val_acc: 0.7100\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4967 - acc: 0.8450 - val_loss: 1.2015 - val_acc: 0.6200\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4990 - acc: 0.8413 - val_loss: 1.1066 - val_acc: 0.6800\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4301 - acc: 0.8612 - val_loss: 0.9225 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.3959 - acc: 0.8725 - val_loss: 0.9575 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.4334 - acc: 0.8563 - val_loss: 0.9463 - val_acc: 0.7800\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.4318 - acc: 0.8400 - val_loss: 0.9829 - val_acc: 0.7600\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3826 - acc: 0.8725 - val_loss: 0.8882 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.4145 - acc: 0.8600 - val_loss: 1.2543 - val_acc: 0.7100\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.4294 - acc: 0.8688 - val_loss: 1.2299 - val_acc: 0.6800\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.4333 - acc: 0.8612 - val_loss: 0.7767 - val_acc: 0.7900\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3443 - acc: 0.8863 - val_loss: 0.9859 - val_acc: 0.6600\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.3954 - acc: 0.8700 - val_loss: 0.9373 - val_acc: 0.7600\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.3953 - acc: 0.8800 - val_loss: 0.8981 - val_acc: 0.7500\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2820 - acc: 0.9012 - val_loss: 1.2487 - val_acc: 0.6500\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.3133 - acc: 0.8912 - val_loss: 0.8317 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2952 - acc: 0.8937 - val_loss: 0.7743 - val_acc: 0.8200\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2410 - acc: 0.9213 - val_loss: 1.8510 - val_acc: 0.5800\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.2775 - acc: 0.9113 - val_loss: 1.0462 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.2608 - acc: 0.9113 - val_loss: 1.0756 - val_acc: 0.7300\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2780 - acc: 0.9213 - val_loss: 1.1571 - val_acc: 0.7600\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.2220 - acc: 0.9375 - val_loss: 0.9887 - val_acc: 0.8300\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.2597 - acc: 0.9175 - val_loss: 1.2767 - val_acc: 0.6700\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.2580 - acc: 0.9137 - val_loss: 1.0012 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.2035 - acc: 0.9300 - val_loss: 0.6288 - val_acc: 0.8900\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1688 - acc: 0.9475 - val_loss: 0.7502 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.2251 - acc: 0.9237 - val_loss: 0.8625 - val_acc: 0.8100\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.2408 - acc: 0.9137 - val_loss: 2.0013 - val_acc: 0.6200\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.2675 - acc: 0.9113 - val_loss: 0.7953 - val_acc: 0.8500\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 30s - loss: 0.2444 - acc: 0.9275 - val_loss: 2.0458 - val_acc: 0.5300\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1405 - acc: 0.9513 - val_loss: 0.6697 - val_acc: 0.7900\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1344 - acc: 0.9650 - val_loss: 0.6342 - val_acc: 0.8600\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.1271 - acc: 0.9637 - val_loss: 0.7278 - val_acc: 0.8300\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 27s - loss: 0.0797 - acc: 0.9788 - val_loss: 0.7327 - val_acc: 0.8500\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.1037 - acc: 0.9688 - val_loss: 0.7583 - val_acc: 0.7900\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1112 - acc: 0.9700 - val_loss: 0.5738 - val_acc: 0.8700\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0862 - acc: 0.9800 - val_loss: 0.7610 - val_acc: 0.8400\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0821 - acc: 0.9775 - val_loss: 0.7136 - val_acc: 0.8800\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0733 - acc: 0.9800 - val_loss: 0.6192 - val_acc: 0.8800\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0611 - acc: 0.9862 - val_loss: 0.6966 - val_acc: 0.8400\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0625 - acc: 0.9875 - val_loss: 0.6528 - val_acc: 0.8800\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0539 - acc: 0.9912 - val_loss: 0.6401 - val_acc: 0.8600\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0668 - acc: 0.9838 - val_loss: 0.6737 - val_acc: 0.8500\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0494 - acc: 0.9900 - val_loss: 0.6392 - val_acc: 0.8400\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0663 - acc: 0.9813 - val_loss: 0.6184 - val_acc: 0.8400\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.0512 - acc: 0.9887 - val_loss: 0.6867 - val_acc: 0.8400\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0904 - acc: 0.9725 - val_loss: 0.7592 - val_acc: 0.8400\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.1290 - acc: 0.9675 - val_loss: 0.8514 - val_acc: 0.8500\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0454 - acc: 0.9912 - val_loss: 0.6612 - val_acc: 0.8500\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0415 - acc: 0.9912 - val_loss: 0.6546 - val_acc: 0.8600\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0472 - acc: 0.9925 - val_loss: 0.6513 - val_acc: 0.8900\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0472 - acc: 0.9887 - val_loss: 0.6661 - val_acc: 0.8500\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0334 - acc: 0.9963 - val_loss: 0.6457 - val_acc: 0.8500\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0377 - acc: 0.9925 - val_loss: 0.6504 - val_acc: 0.8500\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0299 - acc: 0.9975 - val_loss: 0.6471 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0391 - acc: 0.9938 - val_loss: 0.7308 - val_acc: 0.8400\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0381 - acc: 0.9925 - val_loss: 0.6795 - val_acc: 0.8500\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0375 - acc: 0.9938 - val_loss: 0.6763 - val_acc: 0.8500\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0286 - acc: 0.9975 - val_loss: 0.7217 - val_acc: 0.8500\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0707 - acc: 0.9800 - val_loss: 0.7457 - val_acc: 0.8600\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0480 - acc: 0.9850 - val_loss: 0.6821 - val_acc: 0.8600\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 28s - loss: 0.0372 - acc: 0.9950 - val_loss: 0.6527 - val_acc: 0.8700\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 28s - loss: 0.0372 - acc: 0.9938 - val_loss: 0.6925 - val_acc: 0.8500\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 28s - loss: 0.0339 - acc: 0.9912 - val_loss: 0.6880 - val_acc: 0.8500\n",
      "\n",
      "\n",
      "7 fold train loss 0.1049 train acc 0.9637, val loss 0.6288 val acc 0.8900, test loss 0.4774 test acc 0.8700\n",
      "\n",
      "\n",
      "Start 8 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 43s - loss: 1.8476 - acc: 0.3250 - val_loss: 5.7054 - val_acc: 0.2100\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 27s - loss: 1.6225 - acc: 0.4088 - val_loss: 9.4835 - val_acc: 0.1900\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.5187 - acc: 0.4688 - val_loss: 3.6347 - val_acc: 0.2700\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.5117 - acc: 0.4588 - val_loss: 2.3396 - val_acc: 0.2900\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3780 - acc: 0.5212 - val_loss: 2.5260 - val_acc: 0.3900\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.3402 - acc: 0.5225 - val_loss: 1.9818 - val_acc: 0.3900\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.3042 - acc: 0.5400 - val_loss: 2.2309 - val_acc: 0.3700\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.2800 - acc: 0.5588 - val_loss: 3.5580 - val_acc: 0.2700\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.1999 - acc: 0.5863 - val_loss: 1.6968 - val_acc: 0.4700\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.2022 - acc: 0.5837 - val_loss: 2.4309 - val_acc: 0.3500\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.1417 - acc: 0.6150 - val_loss: 1.6495 - val_acc: 0.4300\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 1.0936 - acc: 0.6425 - val_loss: 1.4286 - val_acc: 0.5400\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 1.0291 - acc: 0.6375 - val_loss: 1.5170 - val_acc: 0.4800\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 1.0147 - acc: 0.6650 - val_loss: 1.8050 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 1.0085 - acc: 0.6462 - val_loss: 1.2324 - val_acc: 0.5500\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8835 - acc: 0.7025 - val_loss: 2.9071 - val_acc: 0.4200\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.9512 - acc: 0.6875 - val_loss: 1.2141 - val_acc: 0.5800\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.8756 - acc: 0.7037 - val_loss: 1.4170 - val_acc: 0.5600\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8104 - acc: 0.7163 - val_loss: 1.2048 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.8346 - acc: 0.7200 - val_loss: 2.1981 - val_acc: 0.5500\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.8312 - acc: 0.7212 - val_loss: 1.2126 - val_acc: 0.6300\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.8393 - acc: 0.7050 - val_loss: 1.4713 - val_acc: 0.6300\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7456 - acc: 0.7488 - val_loss: 1.5921 - val_acc: 0.4700\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.7315 - acc: 0.7575 - val_loss: 1.5134 - val_acc: 0.5800\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.7182 - acc: 0.7588 - val_loss: 4.7436 - val_acc: 0.4400\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6960 - acc: 0.7687 - val_loss: 1.1206 - val_acc: 0.6700\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.7119 - acc: 0.7638 - val_loss: 1.0889 - val_acc: 0.6700\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.5869 - acc: 0.7938 - val_loss: 0.8537 - val_acc: 0.7100\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5732 - acc: 0.8238 - val_loss: 0.9482 - val_acc: 0.6800\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.6411 - acc: 0.7788 - val_loss: 1.9256 - val_acc: 0.5900\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5878 - acc: 0.7950 - val_loss: 0.9090 - val_acc: 0.6600\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.6025 - acc: 0.7925 - val_loss: 1.0535 - val_acc: 0.7300\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5652 - acc: 0.8150 - val_loss: 0.9713 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.5649 - acc: 0.8175 - val_loss: 1.3314 - val_acc: 0.6600\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.5072 - acc: 0.8350 - val_loss: 1.5633 - val_acc: 0.5200\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4882 - acc: 0.8312 - val_loss: 1.3159 - val_acc: 0.6700\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4304 - acc: 0.8588 - val_loss: 0.8900 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4640 - acc: 0.8475 - val_loss: 1.2740 - val_acc: 0.6200\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4965 - acc: 0.8312 - val_loss: 4.3883 - val_acc: 0.4400\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.4264 - acc: 0.8512 - val_loss: 1.9225 - val_acc: 0.5900\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.4439 - acc: 0.8588 - val_loss: 1.4394 - val_acc: 0.6300\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.4588 - acc: 0.8488 - val_loss: 1.7631 - val_acc: 0.4900\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.3948 - acc: 0.8662 - val_loss: 0.8511 - val_acc: 0.7700\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.4456 - acc: 0.8538 - val_loss: 1.0688 - val_acc: 0.7200\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.3899 - acc: 0.8688 - val_loss: 1.7098 - val_acc: 0.6600\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3827 - acc: 0.8775 - val_loss: 1.4837 - val_acc: 0.5800\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.3146 - acc: 0.9125 - val_loss: 1.5859 - val_acc: 0.6200\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.3685 - acc: 0.8838 - val_loss: 0.6040 - val_acc: 0.8400\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.3115 - acc: 0.9087 - val_loss: 1.2314 - val_acc: 0.6800\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.2772 - acc: 0.9113 - val_loss: 1.5657 - val_acc: 0.5900\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2500 - acc: 0.9262 - val_loss: 0.7566 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.3339 - acc: 0.9050 - val_loss: 3.3267 - val_acc: 0.5100\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.3239 - acc: 0.8925 - val_loss: 0.9250 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.2518 - acc: 0.9275 - val_loss: 0.9678 - val_acc: 0.7200\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2478 - acc: 0.9275 - val_loss: 1.0736 - val_acc: 0.6600\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.2408 - acc: 0.9163 - val_loss: 1.9845 - val_acc: 0.6300\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.2035 - acc: 0.9450 - val_loss: 0.7649 - val_acc: 0.7600\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.2263 - acc: 0.9250 - val_loss: 1.2937 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.2384 - acc: 0.9188 - val_loss: 1.4454 - val_acc: 0.6300\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.2640 - acc: 0.9113 - val_loss: 0.3960 - val_acc: 0.9000\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 30s - loss: 0.2127 - acc: 0.9363 - val_loss: 0.5758 - val_acc: 0.8200\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1478 - acc: 0.9575 - val_loss: 0.8020 - val_acc: 0.7600\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1254 - acc: 0.9712 - val_loss: 0.4661 - val_acc: 0.8600\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1066 - acc: 0.9738 - val_loss: 0.4170 - val_acc: 0.8600\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1025 - acc: 0.9712 - val_loss: 0.4232 - val_acc: 0.8800\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.0909 - acc: 0.9813 - val_loss: 0.7361 - val_acc: 0.8300\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.1026 - acc: 0.9650 - val_loss: 0.5034 - val_acc: 0.8300\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.0921 - acc: 0.9838 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.0998 - acc: 0.9625 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1151 - acc: 0.9762 - val_loss: 0.5136 - val_acc: 0.8700\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0805 - acc: 0.9813 - val_loss: 0.4074 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0626 - acc: 0.9875 - val_loss: 0.3672 - val_acc: 0.8900\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0671 - acc: 0.9850 - val_loss: 0.4146 - val_acc: 0.8700\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0372 - acc: 1.0000 - val_loss: 0.3563 - val_acc: 0.8800\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0616 - acc: 0.9912 - val_loss: 0.4688 - val_acc: 0.8600\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0454 - acc: 0.9912 - val_loss: 0.4177 - val_acc: 0.8900\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0433 - acc: 0.9912 - val_loss: 0.4008 - val_acc: 0.8800\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0490 - acc: 0.9850 - val_loss: 0.3489 - val_acc: 0.9100\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 27s - loss: 0.0474 - acc: 0.9938 - val_loss: 0.4300 - val_acc: 0.8600\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0634 - acc: 0.9850 - val_loss: 0.4029 - val_acc: 0.8800\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0374 - acc: 0.9912 - val_loss: 0.3727 - val_acc: 0.9100\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0297 - acc: 0.9975 - val_loss: 0.3400 - val_acc: 0.9100\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0511 - acc: 0.9887 - val_loss: 0.3404 - val_acc: 0.8900\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0374 - acc: 0.9963 - val_loss: 0.3612 - val_acc: 0.8900\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0270 - acc: 0.9963 - val_loss: 0.3322 - val_acc: 0.9000\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0336 - acc: 0.9963 - val_loss: 0.3354 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0413 - acc: 0.9912 - val_loss: 0.3799 - val_acc: 0.8900\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0338 - acc: 0.9950 - val_loss: 0.3638 - val_acc: 0.8900\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0385 - acc: 0.9938 - val_loss: 0.4154 - val_acc: 0.8700\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0253 - acc: 0.9975 - val_loss: 0.3601 - val_acc: 0.8900\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0401 - acc: 0.9925 - val_loss: 0.3711 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0304 - acc: 0.9963 - val_loss: 0.3669 - val_acc: 0.8700\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0311 - acc: 0.9963 - val_loss: 0.3516 - val_acc: 0.8900\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0397 - acc: 0.9900 - val_loss: 0.3506 - val_acc: 0.8700\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0341 - acc: 0.9912 - val_loss: 0.3387 - val_acc: 0.8700\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 28s - loss: 0.0339 - acc: 0.9963 - val_loss: 0.3464 - val_acc: 0.8700\n",
      "\n",
      "\n",
      "8 fold train loss 0.0135 train acc 0.9988, val loss 0.3489 val acc 0.9100, test loss 0.2300 test acc 0.9300\n",
      "\n",
      "\n",
      "Start 9 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 45s - loss: 1.8602 - acc: 0.3150 - val_loss: 7.4635 - val_acc: 0.1300\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 28s - loss: 1.6028 - acc: 0.3837 - val_loss: 4.0946 - val_acc: 0.2900\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.5135 - acc: 0.4225 - val_loss: 1.6005 - val_acc: 0.2800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.3630 - acc: 0.5138 - val_loss: 2.5785 - val_acc: 0.3100\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.3499 - acc: 0.5350 - val_loss: 2.4151 - val_acc: 0.4300\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2643 - acc: 0.5238 - val_loss: 2.0217 - val_acc: 0.4400\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2423 - acc: 0.5300 - val_loss: 1.3173 - val_acc: 0.5800\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.2793 - acc: 0.5687 - val_loss: 1.6184 - val_acc: 0.4300\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.2102 - acc: 0.5787 - val_loss: 1.0828 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.1314 - acc: 0.6162 - val_loss: 1.9206 - val_acc: 0.4300\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.1344 - acc: 0.6112 - val_loss: 1.8847 - val_acc: 0.4100\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.9903 - acc: 0.6613 - val_loss: 3.2134 - val_acc: 0.2400\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 1.0162 - acc: 0.6287 - val_loss: 1.6191 - val_acc: 0.5300\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 27s - loss: 0.9682 - acc: 0.6725 - val_loss: 1.9072 - val_acc: 0.4900\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.9678 - acc: 0.6437 - val_loss: 0.9802 - val_acc: 0.6200\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8681 - acc: 0.7150 - val_loss: 2.4651 - val_acc: 0.4700\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.9297 - acc: 0.6775 - val_loss: 2.2993 - val_acc: 0.3600\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.9067 - acc: 0.6787 - val_loss: 1.8032 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8989 - acc: 0.6663 - val_loss: 0.7564 - val_acc: 0.7100\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.8630 - acc: 0.7062 - val_loss: 1.7413 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.8440 - acc: 0.7262 - val_loss: 1.5744 - val_acc: 0.5400\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7751 - acc: 0.7288 - val_loss: 1.3165 - val_acc: 0.5800\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7461 - acc: 0.7500 - val_loss: 0.9807 - val_acc: 0.6700\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6766 - acc: 0.7600 - val_loss: 1.7857 - val_acc: 0.5700\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6790 - acc: 0.7525 - val_loss: 2.1485 - val_acc: 0.4700\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.7332 - acc: 0.7500 - val_loss: 1.1606 - val_acc: 0.6200\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.7240 - acc: 0.7600 - val_loss: 2.7434 - val_acc: 0.4700\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 30s - loss: 0.7007 - acc: 0.7675 - val_loss: 1.0671 - val_acc: 0.6600\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.5605 - acc: 0.8312 - val_loss: 0.6447 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5073 - acc: 0.8400 - val_loss: 0.5288 - val_acc: 0.8300\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5160 - acc: 0.8375 - val_loss: 0.6905 - val_acc: 0.7200\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5139 - acc: 0.8438 - val_loss: 0.4264 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.4611 - acc: 0.8675 - val_loss: 0.5202 - val_acc: 0.8600\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.4315 - acc: 0.8500 - val_loss: 0.4354 - val_acc: 0.8400\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.4522 - acc: 0.8462 - val_loss: 0.5489 - val_acc: 0.7900\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4254 - acc: 0.8662 - val_loss: 0.5356 - val_acc: 0.8900\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.4076 - acc: 0.8787 - val_loss: 0.5168 - val_acc: 0.8500\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.4127 - acc: 0.8637 - val_loss: 0.4469 - val_acc: 0.8400\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4013 - acc: 0.8688 - val_loss: 0.4736 - val_acc: 0.8200\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.4136 - acc: 0.8738 - val_loss: 0.6988 - val_acc: 0.7800\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 28s - loss: 0.3338 - acc: 0.9000 - val_loss: 0.5849 - val_acc: 0.8300\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.3684 - acc: 0.8812 - val_loss: 0.6402 - val_acc: 0.8100\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.3364 - acc: 0.8900 - val_loss: 0.6640 - val_acc: 0.8500\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3316 - acc: 0.8988 - val_loss: 0.6363 - val_acc: 0.8300\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3024 - acc: 0.9075 - val_loss: 0.3506 - val_acc: 0.9100\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.3082 - acc: 0.9100 - val_loss: 0.6098 - val_acc: 0.7700\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 28s - loss: 0.3252 - acc: 0.9038 - val_loss: 0.6249 - val_acc: 0.8600\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 28s - loss: 0.2948 - acc: 0.9062 - val_loss: 0.6076 - val_acc: 0.8500\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2896 - acc: 0.9087 - val_loss: 0.6499 - val_acc: 0.8200\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.3284 - acc: 0.8888 - val_loss: 0.6375 - val_acc: 0.7600\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2371 - acc: 0.9075 - val_loss: 0.5350 - val_acc: 0.8300\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.3182 - acc: 0.8962 - val_loss: 0.4003 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.2386 - acc: 0.9313 - val_loss: 0.4566 - val_acc: 0.8200\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.2720 - acc: 0.9137 - val_loss: 0.6303 - val_acc: 0.7800\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2602 - acc: 0.9125 - val_loss: 0.4619 - val_acc: 0.8400\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.1882 - acc: 0.9537 - val_loss: 0.3733 - val_acc: 0.9100\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.1432 - acc: 0.9650 - val_loss: 0.4385 - val_acc: 0.8800\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.1278 - acc: 0.9688 - val_loss: 0.2762 - val_acc: 0.9200\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1401 - acc: 0.9600 - val_loss: 0.2915 - val_acc: 0.8700\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.1717 - acc: 0.9562 - val_loss: 0.5071 - val_acc: 0.8600\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1247 - acc: 0.9788 - val_loss: 0.2171 - val_acc: 0.9400\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1223 - acc: 0.9725 - val_loss: 0.2197 - val_acc: 0.9200\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1357 - acc: 0.9700 - val_loss: 0.3764 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.1331 - acc: 0.9712 - val_loss: 0.2791 - val_acc: 0.9400\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.1168 - acc: 0.9712 - val_loss: 0.3798 - val_acc: 0.9100\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1420 - acc: 0.9637 - val_loss: 0.3420 - val_acc: 0.8600\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.1263 - acc: 0.9700 - val_loss: 0.2457 - val_acc: 0.9500\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.1327 - acc: 0.9587 - val_loss: 0.2307 - val_acc: 0.9400\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 29s - loss: 0.1092 - acc: 0.9725 - val_loss: 0.2618 - val_acc: 0.8700\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1040 - acc: 0.9762 - val_loss: 0.4941 - val_acc: 0.8800\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.1132 - acc: 0.9712 - val_loss: 0.3987 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.0978 - acc: 0.9688 - val_loss: 0.2794 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.0888 - acc: 0.9750 - val_loss: 0.3624 - val_acc: 0.8900\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.1009 - acc: 0.9762 - val_loss: 0.1800 - val_acc: 0.9500\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.1117 - acc: 0.9675 - val_loss: 0.2611 - val_acc: 0.8800\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0999 - acc: 0.9762 - val_loss: 0.3109 - val_acc: 0.9100\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.1072 - acc: 0.9725 - val_loss: 0.3079 - val_acc: 0.8900\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0840 - acc: 0.9850 - val_loss: 0.2554 - val_acc: 0.9400\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.0711 - acc: 0.9862 - val_loss: 0.2122 - val_acc: 0.9400\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0658 - acc: 0.9900 - val_loss: 0.1827 - val_acc: 0.9600\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0773 - acc: 0.9813 - val_loss: 0.2060 - val_acc: 0.9100\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0651 - acc: 0.9887 - val_loss: 0.1867 - val_acc: 0.9500\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0561 - acc: 0.9900 - val_loss: 0.1946 - val_acc: 0.9400\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0540 - acc: 0.9925 - val_loss: 0.2919 - val_acc: 0.9200\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0634 - acc: 0.9838 - val_loss: 0.2029 - val_acc: 0.9200\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0570 - acc: 0.9813 - val_loss: 0.1735 - val_acc: 0.9500\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0573 - acc: 0.9950 - val_loss: 0.2344 - val_acc: 0.9400\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0443 - acc: 0.9912 - val_loss: 0.2506 - val_acc: 0.9200\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0487 - acc: 0.9912 - val_loss: 0.2994 - val_acc: 0.9200\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0711 - acc: 0.9875 - val_loss: 0.2277 - val_acc: 0.9200\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0569 - acc: 0.9887 - val_loss: 0.1905 - val_acc: 0.9600\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0436 - acc: 0.9900 - val_loss: 0.1865 - val_acc: 0.9200\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0530 - acc: 0.9900 - val_loss: 0.1660 - val_acc: 0.9500\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0650 - acc: 0.9788 - val_loss: 0.2394 - val_acc: 0.9500\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0660 - acc: 0.9788 - val_loss: 0.5634 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 28s - loss: 0.0645 - acc: 0.9887 - val_loss: 0.3261 - val_acc: 0.9100\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 28s - loss: 0.0483 - acc: 0.9925 - val_loss: 0.2488 - val_acc: 0.9400\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 28s - loss: 0.0411 - acc: 0.9925 - val_loss: 0.2289 - val_acc: 0.9300\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 28s - loss: 0.0425 - acc: 0.9875 - val_loss: 0.1982 - val_acc: 0.9400\n",
      "\n",
      "\n",
      "9 fold train loss 0.0177 train acc 0.9975, val loss 0.1827 val acc 0.9600, test loss 0.2030 test acc 0.9200\n",
      "\n",
      "\n",
      "Start 10 fold training\n",
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 47s - loss: 1.7765 - acc: 0.3513 - val_loss: 6.6709 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 27s - loss: 1.5938 - acc: 0.4162 - val_loss: 7.0032 - val_acc: 0.1300\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 28s - loss: 1.4519 - acc: 0.5075 - val_loss: 1.9739 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 28s - loss: 1.3484 - acc: 0.5025 - val_loss: 2.4672 - val_acc: 0.3500\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 28s - loss: 1.2790 - acc: 0.5425 - val_loss: 2.0318 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 28s - loss: 1.2667 - acc: 0.5513 - val_loss: 1.8993 - val_acc: 0.5300\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 28s - loss: 1.2055 - acc: 0.5800 - val_loss: 1.3998 - val_acc: 0.5100\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 28s - loss: 1.1128 - acc: 0.5975 - val_loss: 2.2966 - val_acc: 0.4300\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 28s - loss: 1.0988 - acc: 0.6050 - val_loss: 4.2902 - val_acc: 0.2500\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 28s - loss: 1.0979 - acc: 0.6162 - val_loss: 1.2531 - val_acc: 0.5800\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 28s - loss: 1.0452 - acc: 0.6437 - val_loss: 0.9485 - val_acc: 0.6600\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 28s - loss: 0.9952 - acc: 0.6425 - val_loss: 3.8683 - val_acc: 0.2500\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 28s - loss: 0.9178 - acc: 0.6900 - val_loss: 1.1212 - val_acc: 0.5900\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 28s - loss: 0.8951 - acc: 0.6975 - val_loss: 2.2202 - val_acc: 0.4500\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 28s - loss: 0.8609 - acc: 0.6875 - val_loss: 0.8897 - val_acc: 0.6200\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 28s - loss: 0.8306 - acc: 0.7100 - val_loss: 1.0434 - val_acc: 0.6100\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 28s - loss: 0.8437 - acc: 0.7050 - val_loss: 1.3213 - val_acc: 0.6200\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 28s - loss: 0.7725 - acc: 0.7150 - val_loss: 2.3817 - val_acc: 0.3500\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 28s - loss: 0.8038 - acc: 0.7225 - val_loss: 2.0931 - val_acc: 0.4100\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 28s - loss: 0.7815 - acc: 0.7188 - val_loss: 1.2372 - val_acc: 0.5600\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 28s - loss: 0.7350 - acc: 0.7512 - val_loss: 1.0905 - val_acc: 0.6700\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 28s - loss: 0.7690 - acc: 0.7288 - val_loss: 1.2444 - val_acc: 0.6100\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 28s - loss: 0.7391 - acc: 0.7400 - val_loss: 1.9010 - val_acc: 0.6300\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 28s - loss: 0.6829 - acc: 0.7750 - val_loss: 0.8435 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 28s - loss: 0.6798 - acc: 0.7700 - val_loss: 1.9498 - val_acc: 0.5600\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 28s - loss: 0.6845 - acc: 0.7625 - val_loss: 2.2259 - val_acc: 0.4500\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 28s - loss: 0.7373 - acc: 0.7638 - val_loss: 1.7459 - val_acc: 0.5700\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 28s - loss: 0.6147 - acc: 0.8025 - val_loss: 0.5475 - val_acc: 0.8200\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 28s - loss: 0.7067 - acc: 0.7700 - val_loss: 1.2132 - val_acc: 0.6700\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 28s - loss: 0.5801 - acc: 0.8088 - val_loss: 1.3672 - val_acc: 0.5200\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 28s - loss: 0.5696 - acc: 0.8200 - val_loss: 1.6279 - val_acc: 0.5100\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 28s - loss: 0.5834 - acc: 0.8000 - val_loss: 1.6796 - val_acc: 0.5200\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 28s - loss: 0.5679 - acc: 0.8187 - val_loss: 0.6004 - val_acc: 0.8300\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 28s - loss: 0.5957 - acc: 0.7987 - val_loss: 1.8451 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 28s - loss: 0.5377 - acc: 0.8250 - val_loss: 0.5900 - val_acc: 0.8400\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 28s - loss: 0.4749 - acc: 0.8500 - val_loss: 1.0010 - val_acc: 0.6600\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 28s - loss: 0.5273 - acc: 0.8275 - val_loss: 1.0447 - val_acc: 0.6500\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 28s - loss: 0.5074 - acc: 0.8337 - val_loss: 0.6967 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 28s - loss: 0.4653 - acc: 0.8575 - val_loss: 1.2232 - val_acc: 0.6600\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 28s - loss: 0.5020 - acc: 0.8300 - val_loss: 2.2380 - val_acc: 0.4700\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 28s - loss: 0.4669 - acc: 0.8375 - val_loss: 1.1992 - val_acc: 0.7100\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 28s - loss: 0.4901 - acc: 0.8400 - val_loss: 0.7086 - val_acc: 0.7400\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 28s - loss: 0.4146 - acc: 0.8650 - val_loss: 1.0552 - val_acc: 0.6100\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 28s - loss: 0.3685 - acc: 0.8775 - val_loss: 1.4841 - val_acc: 0.6400\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 28s - loss: 0.3864 - acc: 0.8637 - val_loss: 1.2931 - val_acc: 0.6700\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 28s - loss: 0.4166 - acc: 0.8600 - val_loss: 0.6703 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 29s - loss: 0.4413 - acc: 0.8500 - val_loss: 2.3566 - val_acc: 0.4100\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 31s - loss: 0.4176 - acc: 0.8538 - val_loss: 0.5509 - val_acc: 0.8100\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 28s - loss: 0.2812 - acc: 0.9100 - val_loss: 0.4954 - val_acc: 0.8500\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 28s - loss: 0.3216 - acc: 0.8988 - val_loss: 0.3876 - val_acc: 0.8900\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 28s - loss: 0.2633 - acc: 0.9225 - val_loss: 0.4207 - val_acc: 0.8500\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 28s - loss: 0.2655 - acc: 0.9262 - val_loss: 0.4711 - val_acc: 0.8300\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 28s - loss: 0.2361 - acc: 0.9250 - val_loss: 0.4573 - val_acc: 0.8700\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 28s - loss: 0.2148 - acc: 0.9375 - val_loss: 0.2984 - val_acc: 0.9000\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 28s - loss: 0.2466 - acc: 0.9175 - val_loss: 0.4947 - val_acc: 0.8500\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 28s - loss: 0.2432 - acc: 0.9275 - val_loss: 0.5665 - val_acc: 0.8300\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 28s - loss: 0.1947 - acc: 0.9525 - val_loss: 0.3270 - val_acc: 0.8900\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 28s - loss: 0.2339 - acc: 0.9300 - val_loss: 0.2107 - val_acc: 0.9300\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 28s - loss: 0.1708 - acc: 0.9425 - val_loss: 0.2833 - val_acc: 0.9100\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 28s - loss: 0.2162 - acc: 0.9287 - val_loss: 0.3578 - val_acc: 0.8600\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 28s - loss: 0.1958 - acc: 0.9363 - val_loss: 0.3291 - val_acc: 0.8900\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 28s - loss: 0.1457 - acc: 0.9550 - val_loss: 0.2282 - val_acc: 0.9400\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 28s - loss: 0.1956 - acc: 0.9387 - val_loss: 0.3118 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 28s - loss: 0.2137 - acc: 0.9313 - val_loss: 1.1426 - val_acc: 0.6700\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 28s - loss: 0.2134 - acc: 0.9262 - val_loss: 0.5949 - val_acc: 0.8200\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 28s - loss: 0.1586 - acc: 0.9562 - val_loss: 0.6240 - val_acc: 0.7600\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 28s - loss: 0.1611 - acc: 0.9575 - val_loss: 0.1811 - val_acc: 0.9500\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 28s - loss: 0.1339 - acc: 0.9688 - val_loss: 0.2543 - val_acc: 0.9100\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 28s - loss: 0.1349 - acc: 0.9600 - val_loss: 0.1994 - val_acc: 0.9500\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 28s - loss: 0.1319 - acc: 0.9613 - val_loss: 0.2369 - val_acc: 0.9300\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 28s - loss: 0.0990 - acc: 0.9788 - val_loss: 0.2229 - val_acc: 0.9200\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 28s - loss: 0.1333 - acc: 0.9613 - val_loss: 0.2361 - val_acc: 0.9200\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 28s - loss: 0.1097 - acc: 0.9750 - val_loss: 0.2217 - val_acc: 0.9200\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 28s - loss: 0.0901 - acc: 0.9825 - val_loss: 0.2244 - val_acc: 0.9400\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 28s - loss: 0.0800 - acc: 0.9788 - val_loss: 0.2256 - val_acc: 0.9300\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 28s - loss: 0.0867 - acc: 0.9800 - val_loss: 0.3646 - val_acc: 0.9000\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 28s - loss: 0.0966 - acc: 0.9712 - val_loss: 0.3669 - val_acc: 0.8300\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 28s - loss: 0.0829 - acc: 0.9762 - val_loss: 0.5215 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 28s - loss: 0.1023 - acc: 0.9738 - val_loss: 0.1774 - val_acc: 0.9400\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 28s - loss: 0.0754 - acc: 0.9813 - val_loss: 0.1923 - val_acc: 0.9400\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 28s - loss: 0.0767 - acc: 0.9813 - val_loss: 0.1762 - val_acc: 0.9500\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 28s - loss: 0.0671 - acc: 0.9838 - val_loss: 0.1375 - val_acc: 0.9700\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 28s - loss: 0.0699 - acc: 0.9825 - val_loss: 0.1825 - val_acc: 0.9200\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 28s - loss: 0.0540 - acc: 0.9925 - val_loss: 0.1644 - val_acc: 0.9600\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 28s - loss: 0.0594 - acc: 0.9900 - val_loss: 0.1871 - val_acc: 0.9500\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 28s - loss: 0.0590 - acc: 0.9900 - val_loss: 0.1819 - val_acc: 0.9600\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 28s - loss: 0.0604 - acc: 0.9875 - val_loss: 0.1801 - val_acc: 0.9400\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 28s - loss: 0.0704 - acc: 0.9875 - val_loss: 0.1711 - val_acc: 0.9400\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 28s - loss: 0.0566 - acc: 0.9938 - val_loss: 0.1960 - val_acc: 0.9500\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 28s - loss: 0.0734 - acc: 0.9762 - val_loss: 0.1878 - val_acc: 0.9300\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 28s - loss: 0.0521 - acc: 0.9925 - val_loss: 0.1689 - val_acc: 0.9300\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 28s - loss: 0.0512 - acc: 0.9950 - val_loss: 0.1619 - val_acc: 0.9300\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 28s - loss: 0.0576 - acc: 0.9887 - val_loss: 0.1764 - val_acc: 0.9500\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 28s - loss: 0.0642 - acc: 0.9875 - val_loss: 0.1743 - val_acc: 0.9400\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 28s - loss: 0.0513 - acc: 0.9912 - val_loss: 0.1928 - val_acc: 0.9300\n",
      "\n",
      "\n",
      "10 fold train loss 0.0148 train acc 0.9988, val loss 0.1375 val acc 0.9700, test loss 0.2965 test acc 0.9100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 fold train loss avg 0.0311 train acc avg 0.9941, val loss avg 0.3015 val acc avg 0.9380, test loss avg 0.3235 test acc avg 0.9130\n"
     ]
    }
   ],
   "source": [
    "#without data argumatent\n",
    "k_fold = 10\n",
    "num_classes = 10\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "file_name0 = 'GTZAN_model.hdf5'\n",
    "path  = '/share/音乐分类2/GTZAN/2048log/'\n",
    "csv_name0 = 'GTZAN_csv.csv'\n",
    "train_loss_record = []\n",
    "train_acc_record = []\n",
    "val_loss_record = []\n",
    "val_acc_record = []\n",
    "test_loss_record = []\n",
    "test_acc_record = []\n",
    "for i in range(k_fold):\n",
    "    print('Start %d fold training' % (i+1))\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X_melspec, y, train_size=train_size, \n",
    "                                                                          val_size=val_size, test_size=test_size)\n",
    "    file_name = 'ExtendeBallroom2048/'+str(i)+'_fold_'+file_name0\n",
    "#     log_path  = path+str(i)+'_fold_'+'tensorboard_log'\n",
    "    csv_path  = path+str(i)+'_fold_'+ csv_name0\n",
    "    lr_change = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, min_lr=0.000)\n",
    "    model_checkpoint = ModelCheckpoint(file_name, monitor='val_acc', save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='loss', min_delta=0.01, patience=10, mode='min')\n",
    "    csv_logger = CSVLogger(csv_path)\n",
    "#     tb_cb = TensorBoard(log_dir=log_path, write_images=1, histogram_freq=1)\n",
    "    callbacks =[lr_change, model_checkpoint, early_stopping,csv_logger]\n",
    "    opt = Adam(lr=lr)\n",
    "    model = multi_scale_level_cnn(input_shape=(X_melspec.shape[1], X_melspec.shape[2], X_melspec.shape[3]), \n",
    "                              num_dense_blocks=3, num_conv_filters=32, num_classes=num_classes)\n",
    "    model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'],\n",
    "                optimizer=opt)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "              validation_data=(X_val, y_val), verbose=1,\n",
    "              callbacks=callbacks)\n",
    "    model_best = load_model(file_name)\n",
    "    train_loss, train_acc = model_best.evaluate(X_train, y_train, batch_size=batch_size, verbose=0)\n",
    "    val_loss, val_acc = model_best.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)\n",
    "    test_loss, test_acc = model_best.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    train_loss_record.append(train_loss)\n",
    "    train_acc_record.append(train_acc)\n",
    "    val_loss_record.append(val_loss)\n",
    "    val_acc_record.append(val_acc)\n",
    "    test_loss_record.append(test_loss)\n",
    "    test_acc_record.append(test_acc)\n",
    "    print('\\n\\n%d fold train loss %.4f train acc %.4f, val loss %.4f val acc %.4f, test loss %.4f test acc %.4f\\n\\n' % \n",
    "          (i+1, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "train_loss_avg = np.mean(np.array(train_loss_record))\n",
    "train_acc_avg = np.mean(np.array(train_acc_record))\n",
    "val_loss_avg = np.mean(np.array(val_loss_record))\n",
    "val_acc_avg = np.mean(np.array(val_acc_record))\n",
    "test_loss_avg = np.mean(np.array(test_loss_record))\n",
    "test_acc_avg = np.mean(np.array(test_acc_record))\n",
    "print('\\n\\n%d fold train loss avg %.4f train acc avg %.4f, val loss avg %.4f val acc avg %.4f, test loss avg %.4f test acc avg %.4f' % \n",
    "  (k_fold, train_loss_avg, train_acc_avg, val_loss_avg, val_acc_avg, test_loss_avg, test_acc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 13\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "train_loss_record = []\n",
    "train_acc_record = []\n",
    "val_loss_record = []\n",
    "val_acc_record = []\n",
    "test_loss_record = []\n",
    "test_acc_record = []\n",
    "for i in range(k_fold):\n",
    "    print('Start %d fold training' % (i+1))\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X_melspec, y, train_size=train_size, \n",
    "                                                                          val_size=val_size, test_size=test_size)\n",
    "    model_best = load_model(file_name)\n",
    "    train_loss, train_acc = model_best.evaluate(X_train, y_train,batch_size=batch_size,verbose=0)\n",
    "    val_loss, val_acc = model_best.evaluate(X_val, y_val, batch_size=batch_size,verbose=0)\n",
    "    test_loss, test_acc = model_best.evaluate(X_test, y_test,batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    train_loss_record.append(train_loss)\n",
    "    train_acc_record.append(train_acc)\n",
    "    val_loss_record.append(val_loss)\n",
    "    val_acc_record.append(val_acc)\n",
    "    test_loss_record.append(test_loss)\n",
    "    test_acc_record.append(test_acc)\n",
    "    print('\\n\\n%d fold train loss %.4f train acc %.4f, val loss %.4f val acc %.4f, test loss %.4f test acc %.4f\\n\\n' % \n",
    "          (i+1, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "\n",
    "train_loss_avg = np.mean(np.array(train_loss_record))\n",
    "train_acc_avg = np.mean(np.array(train_acc_record))\n",
    "val_loss_avg = np.mean(np.array(val_loss_record))\n",
    "val_acc_avg = np.mean(np.array(val_acc_record))\n",
    "test_loss_avg = np.mean(np.array(test_loss_record))\n",
    "test_acc_avg = np.mean(np.array(test_acc_record))\n",
    "print('\\n\\n%d fold train loss avg %.4f train acc avg %.4f, val loss avg %.4f val acc avg %.4f, test loss avg %.4f test acc avg %.4f' % \n",
    "  (k_fold, train_loss_avg, train_acc_avg, val_loss_avg, val_acc_avg, test_loss_avg, test_acc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = multi_scale_level_cnn(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), \n",
    "                              num_dense_blocks=3, num_conv_filters=32, num_classes=10)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "opt = Adam(lr=0.0001)\n",
    "lr_change = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=2, min_lr=0.000)\n",
    "train_data_iter = data_iter(X_train, y_train, batch_size)\n",
    "test_data_iter = data_iter(X_test, y_test, batch_size)\n",
    "model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'],\n",
    "            optimizer=opt)\n",
    "\n",
    "for e in range(epochs):\n",
    "    batchs = 0\n",
    "    for X_batch, y_batch in train_data_iter:\n",
    "        model.train_on_batch(X_batch, y_batch)\n",
    "        batchs += 1\n",
    "        if batchs >= len(X_train) / 32:\n",
    "            break\n",
    "    train_evaluation = model.evaluate(X_train, y_train, verbose=0)\n",
    "    val_evaluation = model.evaluate(X_val, y_val, verbose=0)\n",
    "    test_evaluation = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Epoch %d train_loss: %.4f train_acc: %.4f, val_loss: %.4f val_acc: %.4f, test_loss: %.4f, test_acc: %.4f' % \n",
    "          (e+1, train_evaluation[0], train_evaluation[1], val_evaluation[0], val_evaluation[1], test_evaluation[0], test_evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
