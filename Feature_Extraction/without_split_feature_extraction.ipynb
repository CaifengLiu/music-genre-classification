{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_enforce_shape(dataset_rootpath, target_sr):\n",
    "    GENRES = sorted(os.listdir(dataset_rootpath))\n",
    "    for genre in GENRES:\n",
    "        genre_path = os.path.join(dataset_rootpath, genre)\n",
    "        for file in os.listdir(genre_path):\n",
    "            audio, sr = librosa.load(os.path.join(genre_path, file), sr=None)\n",
    "            if sr != target_sr:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "            enforce_shape = len(audio)\n",
    "            return enforce_shape\n",
    "    \n",
    "def load_dataset(dataset_rootpath, target_sr=22050):\n",
    "    GENRES = sorted(os.listdir(dataset_rootpath))\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    enforce_shape = get_enforce_shape(dataset_rootpath, target_sr)\n",
    "    for genre_index, genre in enumerate(GENRES):\n",
    "        label = genre_index + 1\n",
    "        genre_path = os.path.join(dataset_rootpath, genre)\n",
    "        for file in os.listdir(genre_path):\n",
    "            audio, sr = librosa.load(os.path.join(genre_path, file), sr=None)\n",
    "            if sr != target_sr:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "            if len(audio) < enforce_shape:\n",
    "                audio = np.append(audio, np.zeros(shape=(enforce_shape - len(audio)), ))\n",
    "            if len(audio) > enforce_shape:\n",
    "                audio = audio[:enforce_shape]\n",
    "            X.append(audio)\n",
    "            y.append(label)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print('Already process %d music' % count)\n",
    "    return np.array(X, dtype=np.float32), np.array(y)\n",
    "\n",
    "def get_stft_feature(X, frame_size, frame_shift_len):\n",
    "    print('Starting extract stft feature......')\n",
    "    stft_feature = []\n",
    "    count = 0\n",
    "    for audio in X:\n",
    "        audio_stft = librosa.stft(audio, n_fft=frame_size, hop_length=frame_shift_len)\n",
    "        audio_stft = librosa.amplitude_to_db(audio_stft)\n",
    "        audio_stft = audio_stft.T\n",
    "        stft_feature.append(audio_stft)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "                print('Already process %d music' % count)\n",
    "    return np.array(stft_feature, dtype=np.float32)\n",
    "\n",
    "def get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels):\n",
    "    print('Start extract melspectrogram feature......')\n",
    "    melspec_feature = []\n",
    "    count = 0\n",
    "    for audio in X:\n",
    "        audio_melspec = librosa.feature.melspectrogram(audio, sr=target_sr, n_fft=frame_size, hop_length=frame_shift_len)\n",
    "        audio_melspec = librosa.power_to_db(audio_melspec)\n",
    "        audio_melspec = audio_melspec.T\n",
    "        melspec_feature.append(audio_melspec)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "                print('Already process %d music' % count)\n",
    "    return np.array(melspec_feature, dtype=np.float32)\n",
    "\n",
    "def get_mfcc_feature(X, target_sr, frame_size, frame_shift_len, n_mfcc):\n",
    "    print('Start extract mfcc feature......')\n",
    "    mfcc_feature = []\n",
    "    count = 0\n",
    "    for audio in X:\n",
    "        audio_mfcc = librosa.feature.mfcc(audio, n_fft=frame_size, hop_length=frame_shift_len, n_mfcc=n_mfcc)\n",
    "        audio_mfcc = audio_mfcc.T\n",
    "        mfcc_feature.append(audio_mfcc)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "                print('Already process %d music' % count)\n",
    "    return np.array(mfcc_feature, dtype=np.float32)\n",
    "\n",
    "def label_onehot_encode(y):\n",
    "    y_onehot = []\n",
    "    y_unique = sorted(set(y))\n",
    "    num_classes = len(y_unique)\n",
    "    for label in y:\n",
    "        tmp = [0]*num_classes\n",
    "        encode_index = y_unique.index(label)\n",
    "        tmp[encode_index] = 1\n",
    "        y_onehot.append(tmp)\n",
    "    return np.array(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 2048\n",
    "frame_shift_len = 1024\n",
    "dataset_rootpath = '/share/music-datasets/GTZAN/audio/'\n",
    "\n",
    "X, y = load_dataset(dataset_rootpath, target_sr=22050)\n",
    "y_onehot = label_onehot_encode(y)\n",
    "stft_feature = get_stft_feature(X, frame_size, frame_shift_len)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels=128)\n",
    "mfcc_feature = get_mfcc_feature(X, target_sr, frame_size, frame_shift_len, n_mfcc=25)\n",
    "np.save('GTZAN/raw_labes.npy', y)\n",
    "np.save('GTZAN/onehot_labels.npy', y_onehot)\n",
    "np.save('GTZAN/raw_audio.npy', X)\n",
    "np.save('GTZAN/without_split_features/stft_feature_2048.npy', stft_feature)\n",
    "np.save('GTZAN/without_split_features/melspec_feature_2048.npy', melspec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 1024\n",
    "frame_shift_len = 512\n",
    "\n",
    "X = np.load('GTZAN/raw_audio.npy')\n",
    "stft_feature = get_stft_feature(X, frame_size, frame_shift_len)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels=128)\n",
    "mfcc_feature = get_mfcc_feature(X, target_sr, frame_size, frame_shift_len, n_mfcc=25)\n",
    "np.save('GTZAN/without_split_feature/stft_feature_1024.npy', stft_feature)\n",
    "np.save('GTZAN/without_split_feature/melspec_feature_1024.npy', melspec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 4096\n",
    "frame_shift_len = 2048\n",
    "\n",
    "X = np.load('GTZAN/raw_audio.npy')\n",
    "stft_feature = get_stft_feature(X, frame_size, frame_shift_len)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels=128)\n",
    "mfcc_feature = get_mfcc_feature(X, target_sr, frame_size, frame_shift_len, n_mfcc=25)\n",
    "np.save('GTZAN/without_split_features/stft_feature_4096.npy', stft_feature)\n",
    "np.save('GTZAN/without_split_features/melspec_feature_4096.npy', melspec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 2048\n",
    "frame_shift_len = 1024\n",
    "dataset_rootpath = '/share/music-datasets/ExtendedBallroom/audio/'\n",
    "\n",
    "X, y = load_dataset(dataset_rootpath, target_sr=22050)\n",
    "y_onehot = label_onehot_encode(y)\n",
    "stft_feature = get_stft_feature(X, frame_size, frame_shift_len)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels=128)\n",
    "mfcc_feature = get_mfcc_feature(X, target_sr, frame_size, frame_shift_len, n_mfcc=25)\n",
    "np.save('ExtendeBallroom/raw_audio.npy', X)\n",
    "np.save('ExtendeBallroom/raw_labels.npy', y)\n",
    "np.save('ExtendeBallroom/onehot_labels.npy', y_onehot)\n",
    "np.save('ExtendeBallroom/without_split_features/stft_feature_2048.npy', stft_feature)\n",
    "np.save('ExtendeBallroom/without_split_features/melspec_feature_2048.npy', melspec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 1024\n",
    "frame_shift_len = 512\n",
    "\n",
    "X = np.load('ExtendeBallroom/raw_audio.npy')\n",
    "stft_feature = get_stft_feature(X, frame_size, frame_shift_len)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, frame_shift_len, n_mels=128)\n",
    "np.save('ExtendeBallroom/without_split_features/stft_feature_1024.npy', stft_feature)\n",
    "np.save('ExtendeBallroom/without_split_features/melspec_feature_1024.npy', melspec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
