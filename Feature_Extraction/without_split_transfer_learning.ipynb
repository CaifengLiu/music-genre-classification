{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50, InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D, Flatten, Dense, Conv1D, Reshape, Conv2D, MaxPool1D, \\\n",
    "                         Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_max_standard_feature(X):\n",
    "    X_standard = []\n",
    "    for feature in X:\n",
    "        feature_max = np.max(feature)\n",
    "        feature_min = np.min(feature)\n",
    "        feature_standard = (feature - feature_min) / (feature_max - feature_min)\n",
    "        X_standard.append(feature_standard)\n",
    "    return X_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_feature_to_3channel(X, target_img_shape):\n",
    "    X_3channel = []\n",
    "    for feature in X:\n",
    "        feature_3channel = np.zeros(shape=(feature.shape[0], feature.shape[1], 3))\n",
    "        feature_3channel[:,:,0] = feature\n",
    "        feature_3channel[:,:,1] = feature\n",
    "        feature_3channel[:,:,2] = feature\n",
    "        feature_3channel = resize(feature_3channel, output_shape=target_img_shape)\n",
    "        X_3channel.append(feature_3channel)\n",
    "    return np.array(X_3channel, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.get_layer('activation_3').output\n",
    "x = Conv2D(1, 1, activation='relu')(x)\n",
    "x = Reshape(target_shape=(55, 55))(x)\n",
    "\n",
    "x= Conv1D(64, 3, activation='relu')(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPool1D(pool_size=2)(x)\n",
    "\n",
    "x= Conv1D(64, 3, activation='relu')(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPool1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# # let's add a fully-connected layer\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "#freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "X_melspec = np.load('without_split_feature/stft_feature.npy')\n",
    "y = np.load('without_split_feature/onehot_labels.npy')\n",
    "X_melspec_standard = min_max_standard_feature(X_melspec)\n",
    "X_melspec_3channel = trans_feature_to_3channel(X_melspec_standard, (224, 224, 3))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_melspec_3channel, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 230, 230, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "res2a_branch2a (Conv2D)      (None, 55, 55, 64)        4160      \n",
      "_________________________________________________________________\n",
      "bn2a_branch2a (BatchNormaliz (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "res2a_branch2b (Conv2D)      (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn2a_branch2b (BatchNormaliz (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 55, 55, 1)         65        \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 55, 55)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 53, 64)            10624     \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 51, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 23, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 21, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 182,411\n",
      "Trainable params: 131,083\n",
      "Non-trainable params: 51,328\n",
      "_________________________________________________________________\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s - loss: 2.3211 - acc: 0.1100 - val_loss: 2.2585 - val_acc: 0.2267\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s - loss: 2.1964 - acc: 0.1857 - val_loss: 2.0143 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s - loss: 2.0616 - acc: 0.2457 - val_loss: 1.8799 - val_acc: 0.3233\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s - loss: 1.9526 - acc: 0.2743 - val_loss: 1.7948 - val_acc: 0.3433\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s - loss: 1.8718 - acc: 0.3029 - val_loss: 1.7236 - val_acc: 0.3367\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s - loss: 1.7913 - acc: 0.3386 - val_loss: 1.7611 - val_acc: 0.3233\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s - loss: 1.7678 - acc: 0.3343 - val_loss: 1.6912 - val_acc: 0.4033\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s - loss: 1.7425 - acc: 0.3643 - val_loss: 1.7729 - val_acc: 0.3333\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s - loss: 1.7318 - acc: 0.3700 - val_loss: 1.6964 - val_acc: 0.3633\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s - loss: 1.6459 - acc: 0.3929 - val_loss: 1.6289 - val_acc: 0.3800\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s - loss: 1.6473 - acc: 0.4029 - val_loss: 1.6196 - val_acc: 0.4400\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s - loss: 1.6019 - acc: 0.4114 - val_loss: 1.5384 - val_acc: 0.4533\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s - loss: 1.5508 - acc: 0.4071 - val_loss: 1.5091 - val_acc: 0.4533\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s - loss: 1.4740 - acc: 0.4357 - val_loss: 1.5094 - val_acc: 0.4600\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s - loss: 1.4834 - acc: 0.4529 - val_loss: 1.5604 - val_acc: 0.3967\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s - loss: 1.4087 - acc: 0.4729 - val_loss: 1.4760 - val_acc: 0.4700\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s - loss: 1.4917 - acc: 0.4471 - val_loss: 1.6805 - val_acc: 0.3867\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s - loss: 1.4433 - acc: 0.4429 - val_loss: 1.4755 - val_acc: 0.4767\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s - loss: 1.3382 - acc: 0.4986 - val_loss: 1.5306 - val_acc: 0.4767\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s - loss: 1.3011 - acc: 0.5086 - val_loss: 1.5290 - val_acc: 0.4500\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s - loss: 1.3046 - acc: 0.5243 - val_loss: 1.4699 - val_acc: 0.4867\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s - loss: 1.2636 - acc: 0.5300 - val_loss: 1.5230 - val_acc: 0.4933\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s - loss: 1.2691 - acc: 0.5371 - val_loss: 1.4748 - val_acc: 0.4733\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s - loss: 1.2186 - acc: 0.5643 - val_loss: 1.5733 - val_acc: 0.4633\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s - loss: 1.2414 - acc: 0.5557 - val_loss: 1.4536 - val_acc: 0.4567\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s - loss: 1.1842 - acc: 0.5529 - val_loss: 1.3885 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s - loss: 1.1697 - acc: 0.5743 - val_loss: 1.4422 - val_acc: 0.4933\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s - loss: 1.0623 - acc: 0.6229 - val_loss: 1.4554 - val_acc: 0.4900\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s - loss: 1.1176 - acc: 0.6014 - val_loss: 1.4668 - val_acc: 0.4967\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s - loss: 1.1631 - acc: 0.5714 - val_loss: 1.4758 - val_acc: 0.4800\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s - loss: 1.0601 - acc: 0.6286 - val_loss: 1.4590 - val_acc: 0.5167\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s - loss: 1.0432 - acc: 0.6300 - val_loss: 1.4916 - val_acc: 0.4700\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s - loss: 0.9876 - acc: 0.6443 - val_loss: 1.4972 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s - loss: 0.9698 - acc: 0.6557 - val_loss: 1.4850 - val_acc: 0.5133\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s - loss: 0.9194 - acc: 0.6600 - val_loss: 1.5904 - val_acc: 0.5067\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s - loss: 0.9429 - acc: 0.6686 - val_loss: 1.5890 - val_acc: 0.5033\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s - loss: 0.9008 - acc: 0.6643 - val_loss: 1.5888 - val_acc: 0.4933\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s - loss: 0.8403 - acc: 0.6957 - val_loss: 1.5135 - val_acc: 0.5067\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s - loss: 0.9170 - acc: 0.6500 - val_loss: 1.5506 - val_acc: 0.4900\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s - loss: 0.8538 - acc: 0.7014 - val_loss: 1.6146 - val_acc: 0.4900\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s - loss: 0.7983 - acc: 0.7043 - val_loss: 1.5248 - val_acc: 0.4767\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s - loss: 0.8531 - acc: 0.6929 - val_loss: 1.5536 - val_acc: 0.5133\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s - loss: 0.7223 - acc: 0.7414 - val_loss: 1.5300 - val_acc: 0.5267\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s - loss: 0.7344 - acc: 0.7200 - val_loss: 1.7064 - val_acc: 0.4967\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s - loss: 0.7217 - acc: 0.7371 - val_loss: 1.5672 - val_acc: 0.5033\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s - loss: 0.7927 - acc: 0.7043 - val_loss: 1.6084 - val_acc: 0.5033\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s - loss: 0.7153 - acc: 0.7600 - val_loss: 1.4827 - val_acc: 0.5167\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s - loss: 0.6034 - acc: 0.7771 - val_loss: 1.7455 - val_acc: 0.5100\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s - loss: 0.6539 - acc: 0.7700 - val_loss: 1.6934 - val_acc: 0.5067\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s - loss: 0.6158 - acc: 0.7800 - val_loss: 1.7069 - val_acc: 0.4733\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s - loss: 0.5808 - acc: 0.7914 - val_loss: 1.7576 - val_acc: 0.5167\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s - loss: 0.5338 - acc: 0.8129 - val_loss: 1.7501 - val_acc: 0.5333\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s - loss: 0.4644 - acc: 0.8157 - val_loss: 1.7547 - val_acc: 0.5133\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s - loss: 0.4948 - acc: 0.8143 - val_loss: 1.9627 - val_acc: 0.4700\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s - loss: 0.5032 - acc: 0.8229 - val_loss: 1.8230 - val_acc: 0.5133\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s - loss: 0.5501 - acc: 0.7986 - val_loss: 1.7868 - val_acc: 0.5333\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s - loss: 0.5072 - acc: 0.8200 - val_loss: 1.9305 - val_acc: 0.4733\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s - loss: 0.4953 - acc: 0.8200 - val_loss: 1.8566 - val_acc: 0.5200\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s - loss: 0.4239 - acc: 0.8486 - val_loss: 1.8846 - val_acc: 0.5067\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s - loss: 0.4914 - acc: 0.8371 - val_loss: 1.8530 - val_acc: 0.5433\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s - loss: 0.3476 - acc: 0.8900 - val_loss: 1.9750 - val_acc: 0.5433\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s - loss: 0.3005 - acc: 0.8871 - val_loss: 2.1049 - val_acc: 0.5300\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s - loss: 0.3577 - acc: 0.8714 - val_loss: 2.0996 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s - loss: 0.3940 - acc: 0.8571 - val_loss: 1.8021 - val_acc: 0.5300\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s - loss: 0.3920 - acc: 0.8686 - val_loss: 2.1032 - val_acc: 0.5300\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s - loss: 0.3113 - acc: 0.8871 - val_loss: 1.8295 - val_acc: 0.5300\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s - loss: 0.3162 - acc: 0.8729 - val_loss: 2.0149 - val_acc: 0.5433\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s - loss: 0.3068 - acc: 0.8843 - val_loss: 1.8987 - val_acc: 0.5700\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s - loss: 0.2757 - acc: 0.9014 - val_loss: 2.0790 - val_acc: 0.5300\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s - loss: 0.3308 - acc: 0.8814 - val_loss: 1.9335 - val_acc: 0.5267\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s - loss: 0.2370 - acc: 0.9243 - val_loss: 2.0968 - val_acc: 0.5367\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s - loss: 0.2700 - acc: 0.9014 - val_loss: 2.0404 - val_acc: 0.5433\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s - loss: 0.2352 - acc: 0.9243 - val_loss: 2.1106 - val_acc: 0.5267\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s - loss: 0.3218 - acc: 0.8643 - val_loss: 2.0314 - val_acc: 0.5333\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s - loss: 0.2972 - acc: 0.9043 - val_loss: 2.0279 - val_acc: 0.5167\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s - loss: 0.2425 - acc: 0.9229 - val_loss: 1.8401 - val_acc: 0.5533\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s - loss: 0.1736 - acc: 0.9500 - val_loss: 2.1259 - val_acc: 0.5233\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s - loss: 0.2018 - acc: 0.9286 - val_loss: 2.1402 - val_acc: 0.5433\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s - loss: 0.1687 - acc: 0.9486 - val_loss: 2.1450 - val_acc: 0.5400\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s - loss: 0.1383 - acc: 0.9614 - val_loss: 2.2778 - val_acc: 0.5267\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s - loss: 0.1308 - acc: 0.9614 - val_loss: 2.2332 - val_acc: 0.5467\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s - loss: 0.2212 - acc: 0.9171 - val_loss: 2.0093 - val_acc: 0.5900\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s - loss: 0.1320 - acc: 0.9571 - val_loss: 2.2050 - val_acc: 0.5400\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s - loss: 0.2016 - acc: 0.9314 - val_loss: 2.5735 - val_acc: 0.4933\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s - loss: 0.2060 - acc: 0.9314 - val_loss: 2.1316 - val_acc: 0.5333\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s - loss: 0.1514 - acc: 0.9543 - val_loss: 2.2431 - val_acc: 0.5333\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s - loss: 0.1479 - acc: 0.9557 - val_loss: 2.3296 - val_acc: 0.5367\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s - loss: 0.2020 - acc: 0.9343 - val_loss: 2.2666 - val_acc: 0.5200\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s - loss: 0.1761 - acc: 0.9443 - val_loss: 2.0385 - val_acc: 0.5333\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s - loss: 0.1319 - acc: 0.9586 - val_loss: 2.3255 - val_acc: 0.5267\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s - loss: 0.1475 - acc: 0.9557 - val_loss: 2.3149 - val_acc: 0.5300\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s - loss: 0.1401 - acc: 0.9557 - val_loss: 2.4141 - val_acc: 0.5333\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s - loss: 0.1204 - acc: 0.9600 - val_loss: 2.2740 - val_acc: 0.5500\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s - loss: 0.1110 - acc: 0.9614 - val_loss: 2.6386 - val_acc: 0.5467\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s - loss: 0.1367 - acc: 0.9557 - val_loss: 2.3212 - val_acc: 0.5300\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s - loss: 0.1352 - acc: 0.9557 - val_loss: 2.2868 - val_acc: 0.5300\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s - loss: 0.1648 - acc: 0.9457 - val_loss: 2.3989 - val_acc: 0.5167\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s - loss: 0.1305 - acc: 0.9543 - val_loss: 2.3629 - val_acc: 0.5367\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s - loss: 0.1111 - acc: 0.9700 - val_loss: 2.2363 - val_acc: 0.5467\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s - loss: 0.0965 - acc: 0.9714 - val_loss: 2.3416 - val_acc: 0.5467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc0f925d30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
